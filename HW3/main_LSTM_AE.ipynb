{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# SciKit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Graphing\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# utils\n",
    "from utils import *\n",
    "\n",
    "# Device (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f093809da90>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Parameters\n",
    "lr = 1e-3\n",
    "min_lr = 1e-5\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "\n",
    "# Data Parameters\n",
    "data_seq_len = 100\n",
    "data_n_features = 1\n",
    "data_embedding_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2875\n",
      "4000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "#load train data\n",
    "df_sensorA_normal = pd.read_csv('data/sensor_A_normal.csv')\n",
    "df_sensorB_normal = pd.read_csv('data/sensor_B_normal.csv')\n",
    "df_sensorC_normal = pd.read_csv('data/sensor_C_normal.csv')\n",
    "df_sensorD_normal = pd.read_csv('data/sensor_D_normal.csv')\n",
    "df_sensorE_normal = pd.read_csv('data/sensor_E_normal.csv')\n",
    "print(len(df_sensorA_normal))\n",
    "df_train = [df_sensorA_normal, df_sensorB_normal, df_sensorC_normal, df_sensorD_normal, df_sensorE_normal]\n",
    "\n",
    "# load val data\n",
    "df_sensorA_public = pd.read_csv('data/sensor_A_public.csv')\n",
    "df_sensorB_public = pd.read_csv('data/sensor_B_public.csv')\n",
    "df_sensorC_public = pd.read_csv('data/sensor_C_public.csv')\n",
    "df_sensorD_public = pd.read_csv('data/sensor_D_public.csv')\n",
    "df_sensorE_public = pd.read_csv('data/sensor_E_public.csv')\n",
    "print(len(df_sensorA_public))\n",
    "df_test = [df_sensorA_public, df_sensorB_public, df_sensorC_public, df_sensorD_public, df_sensorE_public]\n",
    "\n",
    "# load test data\n",
    "df_sensorA_private = pd.read_csv('data/sensor_A_private.csv')\n",
    "df_sensorB_private = pd.read_csv('data/sensor_B_private.csv')\n",
    "df_sensorC_private = pd.read_csv('data/sensor_C_private.csv')\n",
    "df_sensorD_private = pd.read_csv('data/sensor_D_private.csv')\n",
    "df_sensorE_private = pd.read_csv('data/sensor_E_private.csv')\n",
    "print(len(df_sensorA_private))\n",
    "df_private = [df_sensorA_private, df_sensorB_private, df_sensorC_private, df_sensorD_private, df_sensorE_private]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_test:\n",
    "    df.drop(df.index[-1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SensorDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "        Support class for the loading and batching of sequences of samples\n",
    "\n",
    "        Args:\n",
    "            dataset (Tensor): Tensor containing all the samples\n",
    "            sequence_length (int): length of the analyzed sequence by the LSTM\n",
    "            transforms (object torchvision.transform): Pytorch's transforms used to process the data\n",
    "    \"\"\"\n",
    "    ##  Constructor\n",
    "    def __init__(self, df, seq_len=1, transform=None):\n",
    "        self.dataset = df\n",
    "        self.seq_len = seq_len\n",
    "        self.transforms = transform\n",
    "\n",
    "    ##  Override total dataset's length getter\n",
    "    def __len__(self):\n",
    "        return self.dataset.__len__()\n",
    "\n",
    "    ##  Override single items' getter\n",
    "    def __getitem__(self, idx):\n",
    "        if idx + self.seq_len > len(self.dataset):\n",
    "            if self.transforms is not None:    \n",
    "                item = torch.zeros(self.seq_len, self.dataset[0].__len__())\n",
    "                item[:self.__len__()-idx] = self.transforms(self.dataset[idx:])\n",
    "                return item, item\n",
    "            else:\n",
    "                item = []\n",
    "                item[:self.__len__()-idx] = self.dataset[idx:]\n",
    "                return item, item\n",
    "\n",
    "        else:\n",
    "            if self.transforms is not None:\n",
    "                return self.transforms(self.dataset[idx:idx+self.seq_len]), self.transforms(self.dataset[idx:idx+self.seq_len])\n",
    "            else:\n",
    "                return self.dataset[idx:idx+self.seq_len], self.dataset[idx:idx+self.seq_len]\n",
    "\n",
    "                \n",
    "# Helper for transforming the data from a list to Tensor\n",
    "def listToTensor(list):\n",
    "    tensor = torch.empty(list.__len__(), list[0].__len__())\n",
    "    for i in range(list.__len__()):\n",
    "        tensor[i, :] = torch.from_numpy(list[i])\n",
    "    return tensor \n",
    "\n",
    "# transform\n",
    "data_transform = transforms.Lambda(lambda x: listToTensor(x))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataset Objects\n",
    "train_dataset = []\n",
    "for df in df_train:\n",
    "    data = np.array(df.iloc[:, 0].values).astype(float).reshape(-1, 1)\n",
    "    train_dataset.append(SensorDataset(data, seq_len=data_seq_len, transform = data_transform))\n",
    "val_dataset = []\n",
    "for df in df_test:\n",
    "    data = np.array(df.iloc[:401, 0].values).astype(float).reshape(-1, 1)\n",
    "    val_dataset.append(SensorDataset(data, seq_len=data_seq_len, transform = data_transform))\n",
    "private_dataset = []\n",
    "for df in df_private:\n",
    "    data = np.array(df.iloc[:, 0].values).astype(float).reshape(-1, 1)\n",
    "    private_dataset.append(SensorDataset(data, seq_len=data_seq_len, transform = data_transform))\n",
    "\n",
    "# Pytorch DataLoader objects\n",
    "train_loader = []\n",
    "for dataset in train_dataset:\n",
    "    train_loader.append(DataLoader(dataset, batch_size=batch_size, shuffle=False))\n",
    "val_loader = []\n",
    "for dataset in val_dataset:\n",
    "    val_loader.append(DataLoader(dataset, batch_size=batch_size, shuffle=False))\n",
    "private_loader = []\n",
    "for dataset in private_dataset:\n",
    "    private_loader.append(DataLoader(dataset, batch_size=batch_size, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, seq_len, n_features, embedding_dim):\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        \n",
    "        # Parameters\n",
    "        self.seq_len = seq_len\n",
    "        self.n_features = n_features\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = 2*embedding_dim\n",
    "        \n",
    "        # Neural Network Layers\n",
    "        self.lstm1 = nn.LSTM(self.n_features, self.hidden_dim, num_layers=1, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(self.hidden_dim, self.embedding_dim, num_layers=1, batch_first=True)\n",
    "    \n",
    "    def forward(self, i): \n",
    "        i, _ = self.lstm1(i)               # from (batch, seq_len, n_features) to (batch, seq_len, hidden_dim)\n",
    "        i, (hidden_n, _) = self.lstm2(i)   # from (batch, seq_len, hidden_dim) to (batch, seq_len, embedding_dim)\n",
    "        return hidden_n                    # hidden_n shape: (num_layers*num_directions, batch, embedding_dim)\n",
    "\n",
    "\n",
    "class LSTMDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, seq_len, embedding_dim, n_features=1):\n",
    "        super(LSTMDecoder, self).__init__()\n",
    "\n",
    "        # Parameters\n",
    "        self.seq_len = seq_len\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = 2*embedding_dim\n",
    "        self.n_features = n_features\n",
    "        \n",
    "        # Neural Network Layers\n",
    "        self.lstm1 = nn.LSTM(self.embedding_dim, self.embedding_dim, num_layers=1, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(self.embedding_dim, self.hidden_dim, num_layers=1, batch_first=True)\n",
    "        self.output_layer = nn.Linear(self.hidden_dim, n_features)\n",
    "        \n",
    "    def forward(self, i):\n",
    "        # Do padding\n",
    "        i = i.repeat(self.seq_len, 1, 1)                       # repeat (1, embedding_dim) to (seq_len, embedding_dim)\n",
    "        i = i.reshape((-1, self.seq_len, self.embedding_dim))  # reshape to (batch, seq_len, embedding_dim)\n",
    "        \n",
    "        # Traverse neural layers\n",
    "        i, _ = self.lstm1(i)      # from (batch, seq_len, embedding_dim) to (batch, seq_len, embedding_dim)\n",
    "        i, _ = self.lstm2(i)      # from (batch, seq_len, embedding_dim) to (batch, seq_len, hidden_dim)\n",
    "        i = self.output_layer(i)  # from (batch, seq_len, hidden_dim) to (batch, seq_len, n_features)\n",
    "        \n",
    "        return i\n",
    "\n",
    "\n",
    "class LSTMAutoencoder(nn.Module):\n",
    "    def __init__(self, seq_len, n_features, embedding_dim=64):\n",
    "        super(LSTMAutoencoder, self).__init__()\n",
    "        self.encoder = LSTMEncoder(seq_len, n_features, embedding_dim).to(device)\n",
    "        self.decoder = LSTMDecoder(seq_len, embedding_dim, n_features).to(device)\n",
    "        \n",
    "    def forward(self, i):\n",
    "        i = self.encoder(i)\n",
    "        i = self.decoder(i)\n",
    "        return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model1 for E1\n",
    "model = LSTMAutoencoder(data_seq_len, data_n_features, data_embedding_dim)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "lr_schedule = cosine_scheduler(\n",
    "        lr,\n",
    "        min_lr,\n",
    "        epochs, len(train_loader[0]),\n",
    "        warmup_epochs=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, optimizer, trainset_iterator, validationset_iterator, epoch):\n",
    "    train_losses, test_losses = [], []\n",
    "    criterion = nn.L1Loss(reduction='sum').to(device)\n",
    "\n",
    "    for epoch in range(epoch):\n",
    "        \n",
    "        print(\"Epoch %d training started ...\" % epoch)\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Enter Train Mode\n",
    "        model.train()     \n",
    "        train_loss = 0\n",
    "        for it, (ii, _) in enumerate(trainset_iterator):\n",
    "            #print(ii)\n",
    "            ii = ii.to(device)              # move to GPU if necessary\n",
    "            it = len(trainset_iterator) * epoch + it  # global training iteration\n",
    "            for i, param_group in enumerate(optimizer.param_groups):\n",
    "                param_group[\"lr\"] = lr_schedule[it]\n",
    "            optimizer.zero_grad()           # generate prediction\n",
    "            preds = model(ii)               # generate prediction\n",
    "            loss = criterion(preds, ii)     # calculate loss\n",
    "            loss.backward()                 # back propagation of gradients and update weights\n",
    "            optimizer.step()                # update optimizer\n",
    "            train_loss += loss.item()       # record training losses\n",
    "\n",
    "        # Enter Validation Mode\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for ii, _ in validationset_iterator:\n",
    "                ii = ii.to(device)          # move to GPU if necessary\n",
    "                preds = model(ii)           # generate prediction\n",
    "                loss = criterion(preds, ii) # calculate loss\n",
    "                test_loss += loss           # record validation testing losses\n",
    "        \n",
    "        end_time = time.time()\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        print(\"Epoch %d completed - train_loss: %f , test_loss: %f\" % (epoch, train_loss, test_loss))\n",
    "        print(\"Epoch %d training time: %f\" %(epoch, (end_time - start_time)))\n",
    "    \n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataset_iterator):\n",
    "    preds, losses = np.array([]), np.array([])\n",
    "    criterion = nn.L1Loss(reduction='none').to(device)\n",
    "    \n",
    "    # Enter Validation Mode\n",
    "    model = model.eval()\n",
    "    with torch.no_grad():\n",
    "        for ii, _ in dataset_iterator:\n",
    "            # move to GPU if necessary\n",
    "            ii = ii.to(device)\n",
    "            \n",
    "            # generate prediction\n",
    "            pred = model(ii)\n",
    "            \n",
    "            # calculate loss\n",
    "            loss = criterion(pred, ii)\n",
    "            \n",
    "            # record predictions\n",
    "            preds = np.append(preds, pred[:, -1, :].cpu().numpy())\n",
    "            \n",
    "            # record mean loss of each sample\n",
    "            loss = loss.reshape((-1, data_seq_len)).cpu().numpy()  # from (batch, seq_len, n_feature) to (batch, seq_len)\n",
    "            losses = np.append(losses, [np.sum(i) for i in loss])  # sum of all seq_len losses into one loss\n",
    "    \n",
    "    preds = preds.reshape((-1, dataset_iterator.__len__))  # reshape to (batch, seq_len)\n",
    "    return preds, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training started ...\n",
      "Epoch 0 completed - train_loss: 218496.298828 , test_loss: 279288.187500\n",
      "Epoch 0 training time: 5.816305\n",
      "Epoch 1 training started ...\n",
      "Epoch 1 completed - train_loss: 215234.703125 , test_loss: 271115.531250\n",
      "Epoch 1 training time: 5.726530\n",
      "Epoch 2 training started ...\n",
      "Epoch 2 completed - train_loss: 207613.662109 , test_loss: 255969.859375\n",
      "Epoch 2 training time: 5.701616\n",
      "Epoch 3 training started ...\n",
      "Epoch 3 completed - train_loss: 193724.263672 , test_loss: 227306.171875\n",
      "Epoch 3 training time: 5.711325\n",
      "Epoch 4 training started ...\n",
      "Epoch 4 completed - train_loss: 163961.347656 , test_loss: 152052.703125\n",
      "Epoch 4 training time: 5.706374\n",
      "Epoch 5 training started ...\n",
      "Epoch 5 completed - train_loss: 121374.203125 , test_loss: 152850.359375\n",
      "Epoch 5 training time: 5.699254\n",
      "Epoch 6 training started ...\n",
      "Epoch 6 completed - train_loss: 121784.672852 , test_loss: 168966.625000\n",
      "Epoch 6 training time: 5.717803\n",
      "Epoch 7 training started ...\n",
      "Epoch 7 completed - train_loss: 114341.836914 , test_loss: 151849.703125\n",
      "Epoch 7 training time: 5.788274\n",
      "Epoch 8 training started ...\n",
      "Epoch 8 completed - train_loss: 115043.181641 , test_loss: 175464.703125\n",
      "Epoch 8 training time: 5.699114\n",
      "Epoch 9 training started ...\n",
      "Epoch 9 completed - train_loss: 113042.485352 , test_loss: 162762.781250\n",
      "Epoch 9 training time: 5.643353\n",
      "Epoch 10 training started ...\n",
      "Epoch 10 completed - train_loss: 112054.811523 , test_loss: 159842.781250\n",
      "Epoch 10 training time: 5.613398\n",
      "Epoch 11 training started ...\n",
      "Epoch 11 completed - train_loss: 112448.270508 , test_loss: 165919.750000\n",
      "Epoch 11 training time: 5.613813\n",
      "Epoch 12 training started ...\n",
      "Epoch 12 completed - train_loss: 111960.999023 , test_loss: 167145.375000\n",
      "Epoch 12 training time: 5.607669\n",
      "Epoch 13 training started ...\n",
      "Epoch 13 completed - train_loss: 111535.564453 , test_loss: 163236.359375\n",
      "Epoch 13 training time: 5.678465\n",
      "Epoch 14 training started ...\n",
      "Epoch 14 completed - train_loss: 111523.369141 , test_loss: 163288.156250\n",
      "Epoch 14 training time: 5.684063\n",
      "Epoch 15 training started ...\n",
      "Epoch 15 completed - train_loss: 111613.168945 , test_loss: 165318.234375\n",
      "Epoch 15 training time: 5.766215\n",
      "Epoch 16 training started ...\n",
      "Epoch 16 completed - train_loss: 111444.982422 , test_loss: 166027.281250\n",
      "Epoch 16 training time: 5.661849\n",
      "Epoch 17 training started ...\n",
      "Epoch 17 completed - train_loss: 111220.948242 , test_loss: 164423.750000\n",
      "Epoch 17 training time: 5.720927\n",
      "Epoch 18 training started ...\n",
      "Epoch 18 completed - train_loss: 111175.205078 , test_loss: 163902.406250\n",
      "Epoch 18 training time: 5.666969\n",
      "Epoch 19 training started ...\n",
      "Epoch 19 completed - train_loss: 111195.991211 , test_loss: 164011.859375\n",
      "Epoch 19 training time: 5.650169\n",
      "Epoch 20 training started ...\n",
      "Epoch 20 completed - train_loss: 111164.062500 , test_loss: 164092.312500\n",
      "Epoch 20 training time: 5.644575\n",
      "Epoch 21 training started ...\n",
      "Epoch 21 completed - train_loss: 111145.278320 , test_loss: 165069.062500\n",
      "Epoch 21 training time: 5.727568\n",
      "Epoch 22 training started ...\n",
      "Epoch 22 completed - train_loss: 111052.884766 , test_loss: 165403.531250\n",
      "Epoch 22 training time: 5.670875\n",
      "Epoch 23 training started ...\n",
      "Epoch 23 completed - train_loss: 110953.052734 , test_loss: 164849.218750\n",
      "Epoch 23 training time: 5.787425\n",
      "Epoch 24 training started ...\n",
      "Epoch 24 completed - train_loss: 110888.101562 , test_loss: 164216.890625\n",
      "Epoch 24 training time: 5.777179\n",
      "Epoch 25 training started ...\n",
      "Epoch 25 completed - train_loss: 110885.322266 , test_loss: 164203.468750\n",
      "Epoch 25 training time: 5.693376\n",
      "Epoch 26 training started ...\n",
      "Epoch 26 completed - train_loss: 110867.832031 , test_loss: 164330.968750\n",
      "Epoch 26 training time: 5.671054\n",
      "Epoch 27 training started ...\n",
      "Epoch 27 completed - train_loss: 110825.312500 , test_loss: 164424.984375\n",
      "Epoch 27 training time: 5.713817\n",
      "Epoch 28 training started ...\n",
      "Epoch 28 completed - train_loss: 110787.249023 , test_loss: 164709.437500\n",
      "Epoch 28 training time: 5.598917\n",
      "Epoch 29 training started ...\n",
      "Epoch 29 completed - train_loss: 110713.337891 , test_loss: 164340.171875\n",
      "Epoch 29 training time: 5.608029\n",
      "Epoch 30 training started ...\n",
      "Epoch 30 completed - train_loss: 110678.943359 , test_loss: 164238.953125\n",
      "Epoch 30 training time: 5.632328\n",
      "Epoch 31 training started ...\n",
      "Epoch 31 completed - train_loss: 110647.851562 , test_loss: 164305.343750\n",
      "Epoch 31 training time: 5.676762\n",
      "Epoch 32 training started ...\n",
      "Epoch 32 completed - train_loss: 110598.462891 , test_loss: 164245.515625\n",
      "Epoch 32 training time: 5.725584\n",
      "Epoch 33 training started ...\n",
      "Epoch 33 completed - train_loss: 110554.524414 , test_loss: 164125.078125\n",
      "Epoch 33 training time: 5.673064\n",
      "Epoch 34 training started ...\n",
      "Epoch 34 completed - train_loss: 110529.857422 , test_loss: 164113.000000\n",
      "Epoch 34 training time: 5.815326\n",
      "Epoch 35 training started ...\n",
      "Epoch 35 completed - train_loss: 110506.359375 , test_loss: 164306.406250\n",
      "Epoch 35 training time: 5.731907\n",
      "Epoch 36 training started ...\n",
      "Epoch 36 completed - train_loss: 110455.242188 , test_loss: 164154.828125\n",
      "Epoch 36 training time: 5.633178\n",
      "Epoch 37 training started ...\n",
      "Epoch 37 completed - train_loss: 110417.954102 , test_loss: 164038.750000\n",
      "Epoch 37 training time: 5.588254\n",
      "Epoch 38 training started ...\n",
      "Epoch 38 completed - train_loss: 110391.541016 , test_loss: 164107.515625\n",
      "Epoch 38 training time: 5.595758\n",
      "Epoch 39 training started ...\n",
      "Epoch 39 completed - train_loss: 110353.428711 , test_loss: 164095.000000\n",
      "Epoch 39 training time: 5.623456\n",
      "Epoch 40 training started ...\n",
      "Epoch 40 completed - train_loss: 110314.250000 , test_loss: 164119.125000\n",
      "Epoch 40 training time: 5.622231\n",
      "Epoch 41 training started ...\n",
      "Epoch 41 completed - train_loss: 110276.355469 , test_loss: 164063.562500\n",
      "Epoch 41 training time: 5.720158\n",
      "Epoch 42 training started ...\n",
      "Epoch 42 completed - train_loss: 110248.710938 , test_loss: 164092.187500\n",
      "Epoch 42 training time: 5.544744\n",
      "Epoch 43 training started ...\n",
      "Epoch 43 completed - train_loss: 110212.976562 , test_loss: 164058.328125\n",
      "Epoch 43 training time: 5.616028\n",
      "Epoch 44 training started ...\n",
      "Epoch 44 completed - train_loss: 110180.991211 , test_loss: 164057.687500\n",
      "Epoch 44 training time: 5.767796\n",
      "Epoch 45 training started ...\n",
      "Epoch 45 completed - train_loss: 110146.609375 , test_loss: 164023.234375\n",
      "Epoch 45 training time: 5.701471\n",
      "Epoch 46 training started ...\n",
      "Epoch 46 completed - train_loss: 110106.423828 , test_loss: 163939.156250\n",
      "Epoch 46 training time: 5.683979\n",
      "Epoch 47 training started ...\n",
      "Epoch 47 completed - train_loss: 110070.304688 , test_loss: 163875.171875\n",
      "Epoch 47 training time: 5.665861\n",
      "Epoch 48 training started ...\n",
      "Epoch 48 completed - train_loss: 110045.195312 , test_loss: 163947.343750\n",
      "Epoch 48 training time: 5.670007\n",
      "Epoch 49 training started ...\n",
      "Epoch 49 completed - train_loss: 110008.713867 , test_loss: 164073.156250\n",
      "Epoch 49 training time: 5.614783\n",
      "Epoch 50 training started ...\n",
      "Epoch 50 completed - train_loss: 109964.935547 , test_loss: 164056.140625\n",
      "Epoch 50 training time: 5.588884\n",
      "Epoch 51 training started ...\n",
      "Epoch 51 completed - train_loss: 109936.351562 , test_loss: 164187.062500\n",
      "Epoch 51 training time: 5.600517\n",
      "Epoch 52 training started ...\n",
      "Epoch 52 completed - train_loss: 109902.676758 , test_loss: 164196.421875\n",
      "Epoch 52 training time: 5.633273\n",
      "Epoch 53 training started ...\n",
      "Epoch 53 completed - train_loss: 109870.210938 , test_loss: 164198.921875\n",
      "Epoch 53 training time: 5.692685\n",
      "Epoch 54 training started ...\n",
      "Epoch 54 completed - train_loss: 109839.012695 , test_loss: 164117.828125\n",
      "Epoch 54 training time: 5.625373\n",
      "Epoch 55 training started ...\n",
      "Epoch 55 completed - train_loss: 109806.543945 , test_loss: 163953.359375\n",
      "Epoch 55 training time: 5.621052\n",
      "Epoch 56 training started ...\n",
      "Epoch 56 completed - train_loss: 109790.259766 , test_loss: 164143.140625\n",
      "Epoch 56 training time: 5.702507\n",
      "Epoch 57 training started ...\n",
      "Epoch 57 completed - train_loss: 109743.791016 , test_loss: 163969.375000\n",
      "Epoch 57 training time: 5.706307\n",
      "Epoch 58 training started ...\n",
      "Epoch 58 completed - train_loss: 109703.009766 , test_loss: 163782.906250\n",
      "Epoch 58 training time: 5.730239\n",
      "Epoch 59 training started ...\n",
      "Epoch 59 completed - train_loss: 109672.899414 , test_loss: 163733.000000\n",
      "Epoch 59 training time: 5.737758\n",
      "Epoch 60 training started ...\n",
      "Epoch 60 completed - train_loss: 109652.103516 , test_loss: 163745.328125\n",
      "Epoch 60 training time: 5.665248\n",
      "Epoch 61 training started ...\n",
      "Epoch 61 completed - train_loss: 109623.415039 , test_loss: 163614.328125\n",
      "Epoch 61 training time: 5.766260\n",
      "Epoch 62 training started ...\n",
      "Epoch 62 completed - train_loss: 109606.268555 , test_loss: 163720.875000\n",
      "Epoch 62 training time: 5.682872\n",
      "Epoch 63 training started ...\n",
      "Epoch 63 completed - train_loss: 109578.514648 , test_loss: 163632.796875\n",
      "Epoch 63 training time: 5.822449\n",
      "Epoch 64 training started ...\n",
      "Epoch 64 completed - train_loss: 109554.058594 , test_loss: 163528.625000\n",
      "Epoch 64 training time: 5.794051\n",
      "Epoch 65 training started ...\n",
      "Epoch 65 completed - train_loss: 109542.275391 , test_loss: 163727.031250\n",
      "Epoch 65 training time: 5.741682\n",
      "Epoch 66 training started ...\n",
      "Epoch 66 completed - train_loss: 109507.525391 , test_loss: 163471.296875\n",
      "Epoch 66 training time: 5.709183\n",
      "Epoch 67 training started ...\n",
      "Epoch 67 completed - train_loss: 109498.458008 , test_loss: 163601.265625\n",
      "Epoch 67 training time: 5.729078\n",
      "Epoch 68 training started ...\n",
      "Epoch 68 completed - train_loss: 109469.555664 , test_loss: 163518.734375\n",
      "Epoch 68 training time: 5.768351\n",
      "Epoch 69 training started ...\n",
      "Epoch 69 completed - train_loss: 109454.497070 , test_loss: 163552.609375\n",
      "Epoch 69 training time: 5.693211\n",
      "Epoch 70 training started ...\n",
      "Epoch 70 completed - train_loss: 109419.082031 , test_loss: 163209.468750\n",
      "Epoch 70 training time: 5.697468\n",
      "Epoch 71 training started ...\n",
      "Epoch 71 completed - train_loss: 109425.880859 , test_loss: 163682.421875\n",
      "Epoch 71 training time: 5.758415\n",
      "Epoch 72 training started ...\n",
      "Epoch 72 completed - train_loss: 109379.462891 , test_loss: 162991.437500\n",
      "Epoch 72 training time: 5.741689\n",
      "Epoch 73 training started ...\n",
      "Epoch 73 completed - train_loss: 109389.741211 , test_loss: 163608.625000\n",
      "Epoch 73 training time: 5.717510\n",
      "Epoch 74 training started ...\n",
      "Epoch 74 completed - train_loss: 109349.155273 , test_loss: 163009.515625\n",
      "Epoch 74 training time: 5.786005\n",
      "Epoch 75 training started ...\n",
      "Epoch 75 completed - train_loss: 109361.031250 , test_loss: 163548.453125\n",
      "Epoch 75 training time: 5.744259\n",
      "Epoch 76 training started ...\n",
      "Epoch 76 completed - train_loss: 109323.496094 , test_loss: 163081.656250\n",
      "Epoch 76 training time: 5.732751\n",
      "Epoch 77 training started ...\n",
      "Epoch 77 completed - train_loss: 109324.312500 , test_loss: 163218.390625\n",
      "Epoch 77 training time: 5.737485\n",
      "Epoch 78 training started ...\n",
      "Epoch 78 completed - train_loss: 109307.306641 , test_loss: 163234.546875\n",
      "Epoch 78 training time: 5.765489\n",
      "Epoch 79 training started ...\n",
      "Epoch 79 completed - train_loss: 109294.895508 , test_loss: 163092.078125\n",
      "Epoch 79 training time: 5.779121\n",
      "Epoch 80 training started ...\n",
      "Epoch 80 completed - train_loss: 109289.541016 , test_loss: 163305.312500\n",
      "Epoch 80 training time: 5.773544\n",
      "Epoch 81 training started ...\n",
      "Epoch 81 completed - train_loss: 109273.097656 , test_loss: 163109.312500\n",
      "Epoch 81 training time: 5.707152\n",
      "Epoch 82 training started ...\n",
      "Epoch 82 completed - train_loss: 109268.516602 , test_loss: 163126.968750\n",
      "Epoch 82 training time: 5.731585\n",
      "Epoch 83 training started ...\n",
      "Epoch 83 completed - train_loss: 109260.604492 , test_loss: 163173.593750\n",
      "Epoch 83 training time: 5.704466\n",
      "Epoch 84 training started ...\n",
      "Epoch 84 completed - train_loss: 109251.915039 , test_loss: 163118.000000\n",
      "Epoch 84 training time: 5.676694\n",
      "Epoch 85 training started ...\n",
      "Epoch 85 completed - train_loss: 109246.072266 , test_loss: 163094.687500\n",
      "Epoch 85 training time: 5.723612\n",
      "Epoch 86 training started ...\n",
      "Epoch 86 completed - train_loss: 109240.791016 , test_loss: 163109.093750\n",
      "Epoch 86 training time: 5.778959\n",
      "Epoch 87 training started ...\n",
      "Epoch 87 completed - train_loss: 109235.313477 , test_loss: 163103.671875\n",
      "Epoch 87 training time: 5.819268\n",
      "Epoch 88 training started ...\n",
      "Epoch 88 completed - train_loss: 109230.625977 , test_loss: 163091.328125\n",
      "Epoch 88 training time: 5.692903\n",
      "Epoch 89 training started ...\n",
      "Epoch 89 completed - train_loss: 109226.707031 , test_loss: 163087.218750\n",
      "Epoch 89 training time: 5.711091\n",
      "Epoch 90 training started ...\n",
      "Epoch 90 completed - train_loss: 109222.841797 , test_loss: 163068.093750\n",
      "Epoch 90 training time: 5.703846\n",
      "Epoch 91 training started ...\n",
      "Epoch 91 completed - train_loss: 109220.041016 , test_loss: 163058.953125\n",
      "Epoch 91 training time: 5.711373\n",
      "Epoch 92 training started ...\n",
      "Epoch 92 completed - train_loss: 109217.404297 , test_loss: 163057.562500\n",
      "Epoch 92 training time: 5.610878\n",
      "Epoch 93 training started ...\n",
      "Epoch 93 completed - train_loss: 109214.826172 , test_loss: 163036.750000\n",
      "Epoch 93 training time: 5.584767\n",
      "Epoch 94 training started ...\n",
      "Epoch 94 completed - train_loss: 109213.240234 , test_loss: 163035.531250\n",
      "Epoch 94 training time: 5.597561\n",
      "Epoch 95 training started ...\n",
      "Epoch 95 completed - train_loss: 109211.511719 , test_loss: 163030.312500\n",
      "Epoch 95 training time: 5.646003\n",
      "Epoch 96 training started ...\n",
      "Epoch 96 completed - train_loss: 109210.144531 , test_loss: 163021.343750\n",
      "Epoch 96 training time: 5.694896\n",
      "Epoch 97 training started ...\n",
      "Epoch 97 completed - train_loss: 109209.142578 , test_loss: 163016.687500\n",
      "Epoch 97 training time: 5.738349\n",
      "Epoch 98 training started ...\n",
      "Epoch 98 completed - train_loss: 109208.318359 , test_loss: 163014.781250\n",
      "Epoch 98 training time: 5.660848\n",
      "Epoch 99 training started ...\n",
      "Epoch 99 completed - train_loss: 109207.632812 , test_loss: 163012.843750\n",
      "Epoch 99 training time: 5.684174\n",
      "Epoch 0 training started ...\n",
      "Epoch 0 completed - train_loss: 369216.585938 , test_loss: 461229.437500\n",
      "Epoch 0 training time: 5.686383\n",
      "Epoch 1 training started ...\n",
      "Epoch 1 completed - train_loss: 298532.453125 , test_loss: 309734.843750\n",
      "Epoch 1 training time: 5.645156\n",
      "Epoch 2 training started ...\n",
      "Epoch 2 completed - train_loss: 184347.829102 , test_loss: 156816.890625\n",
      "Epoch 2 training time: 5.645230\n",
      "Epoch 3 training started ...\n",
      "Epoch 3 completed - train_loss: 103858.679688 , test_loss: 167355.578125\n",
      "Epoch 3 training time: 5.641957\n",
      "Epoch 4 training started ...\n",
      "Epoch 4 completed - train_loss: 98550.858398 , test_loss: 126116.398438\n",
      "Epoch 4 training time: 5.649388\n",
      "Epoch 5 training started ...\n",
      "Epoch 5 completed - train_loss: 95638.772461 , test_loss: 130018.609375\n",
      "Epoch 5 training time: 5.673604\n",
      "Epoch 6 training started ...\n",
      "Epoch 6 completed - train_loss: 94853.500977 , test_loss: 122605.437500\n",
      "Epoch 6 training time: 5.699036\n",
      "Epoch 7 training started ...\n",
      "Epoch 7 completed - train_loss: 90967.211914 , test_loss: 126565.695312\n",
      "Epoch 7 training time: 5.763982\n",
      "Epoch 8 training started ...\n",
      "Epoch 8 completed - train_loss: 91149.608398 , test_loss: 122674.382812\n",
      "Epoch 8 training time: 5.736176\n",
      "Epoch 9 training started ...\n",
      "Epoch 9 completed - train_loss: 90624.493164 , test_loss: 122373.656250\n",
      "Epoch 9 training time: 5.791708\n",
      "Epoch 10 training started ...\n",
      "Epoch 10 completed - train_loss: 90815.323242 , test_loss: 122209.507812\n",
      "Epoch 10 training time: 5.728713\n",
      "Epoch 11 training started ...\n",
      "Epoch 11 completed - train_loss: 90436.179688 , test_loss: 123497.398438\n",
      "Epoch 11 training time: 5.726960\n",
      "Epoch 12 training started ...\n",
      "Epoch 12 completed - train_loss: 90422.629883 , test_loss: 122749.335938\n",
      "Epoch 12 training time: 5.690897\n",
      "Epoch 13 training started ...\n",
      "Epoch 13 completed - train_loss: 90354.505859 , test_loss: 122186.609375\n",
      "Epoch 13 training time: 5.722814\n",
      "Epoch 14 training started ...\n",
      "Epoch 14 completed - train_loss: 90389.398438 , test_loss: 122460.757812\n",
      "Epoch 14 training time: 5.746893\n",
      "Epoch 15 training started ...\n",
      "Epoch 15 completed - train_loss: 90338.209961 , test_loss: 122782.156250\n",
      "Epoch 15 training time: 5.702604\n",
      "Epoch 16 training started ...\n",
      "Epoch 16 completed - train_loss: 90318.406250 , test_loss: 122533.070312\n",
      "Epoch 16 training time: 5.695351\n",
      "Epoch 17 training started ...\n",
      "Epoch 17 completed - train_loss: 90315.502930 , test_loss: 122332.687500\n",
      "Epoch 17 training time: 5.685350\n",
      "Epoch 18 training started ...\n",
      "Epoch 18 completed - train_loss: 90323.045898 , test_loss: 122478.968750\n",
      "Epoch 18 training time: 5.692017\n",
      "Epoch 19 training started ...\n",
      "Epoch 19 completed - train_loss: 90300.846680 , test_loss: 122571.484375\n",
      "Epoch 19 training time: 5.677972\n",
      "Epoch 20 training started ...\n",
      "Epoch 20 completed - train_loss: 90290.385742 , test_loss: 122463.359375\n",
      "Epoch 20 training time: 5.693130\n",
      "Epoch 21 training started ...\n",
      "Epoch 21 completed - train_loss: 90287.691406 , test_loss: 122407.500000\n",
      "Epoch 21 training time: 5.693239\n",
      "Epoch 22 training started ...\n",
      "Epoch 22 completed - train_loss: 90284.192383 , test_loss: 122463.117188\n",
      "Epoch 22 training time: 5.687171\n",
      "Epoch 23 training started ...\n",
      "Epoch 23 completed - train_loss: 90273.945312 , test_loss: 122458.515625\n",
      "Epoch 23 training time: 5.695076\n",
      "Epoch 24 training started ...\n",
      "Epoch 24 completed - train_loss: 90268.281250 , test_loss: 122416.890625\n",
      "Epoch 24 training time: 5.697578\n",
      "Epoch 25 training started ...\n",
      "Epoch 25 completed - train_loss: 90264.437500 , test_loss: 122404.671875\n",
      "Epoch 25 training time: 5.684158\n",
      "Epoch 26 training started ...\n",
      "Epoch 26 completed - train_loss: 90259.190430 , test_loss: 122415.179688\n",
      "Epoch 26 training time: 5.694341\n",
      "Epoch 27 training started ...\n",
      "Epoch 27 completed - train_loss: 90252.229492 , test_loss: 122415.531250\n",
      "Epoch 27 training time: 5.683828\n",
      "Epoch 28 training started ...\n",
      "Epoch 28 completed - train_loss: 90246.588867 , test_loss: 122399.304688\n",
      "Epoch 28 training time: 5.741919\n",
      "Epoch 29 training started ...\n",
      "Epoch 29 completed - train_loss: 90241.973633 , test_loss: 122381.593750\n",
      "Epoch 29 training time: 5.698222\n",
      "Epoch 30 training started ...\n",
      "Epoch 30 completed - train_loss: 90237.898438 , test_loss: 122377.843750\n",
      "Epoch 30 training time: 5.681990\n",
      "Epoch 31 training started ...\n",
      "Epoch 31 completed - train_loss: 90232.458984 , test_loss: 122375.953125\n",
      "Epoch 31 training time: 5.716938\n",
      "Epoch 32 training started ...\n",
      "Epoch 32 completed - train_loss: 90227.419922 , test_loss: 122367.601562\n",
      "Epoch 32 training time: 5.711024\n",
      "Epoch 33 training started ...\n",
      "Epoch 33 completed - train_loss: 90223.122070 , test_loss: 122358.953125\n",
      "Epoch 33 training time: 5.715704\n",
      "Epoch 34 training started ...\n",
      "Epoch 34 completed - train_loss: 90218.942383 , test_loss: 122355.593750\n",
      "Epoch 34 training time: 5.698708\n",
      "Epoch 35 training started ...\n",
      "Epoch 35 completed - train_loss: 90213.864258 , test_loss: 122347.859375\n",
      "Epoch 35 training time: 5.695032\n",
      "Epoch 36 training started ...\n",
      "Epoch 36 completed - train_loss: 90210.005859 , test_loss: 122340.921875\n",
      "Epoch 36 training time: 5.689322\n",
      "Epoch 37 training started ...\n",
      "Epoch 37 completed - train_loss: 90205.340820 , test_loss: 122337.000000\n",
      "Epoch 37 training time: 5.695015\n",
      "Epoch 38 training started ...\n",
      "Epoch 38 completed - train_loss: 90200.972656 , test_loss: 122328.921875\n",
      "Epoch 38 training time: 5.684487\n",
      "Epoch 39 training started ...\n",
      "Epoch 39 completed - train_loss: 90196.967773 , test_loss: 122332.984375\n",
      "Epoch 39 training time: 5.691828\n",
      "Epoch 40 training started ...\n",
      "Epoch 40 completed - train_loss: 90192.539062 , test_loss: 122316.781250\n",
      "Epoch 40 training time: 5.690214\n",
      "Epoch 41 training started ...\n",
      "Epoch 41 completed - train_loss: 90188.986328 , test_loss: 122325.960938\n",
      "Epoch 41 training time: 5.683645\n",
      "Epoch 42 training started ...\n",
      "Epoch 42 completed - train_loss: 90184.834961 , test_loss: 122307.742188\n",
      "Epoch 42 training time: 5.676756\n",
      "Epoch 43 training started ...\n",
      "Epoch 43 completed - train_loss: 90181.443359 , test_loss: 122314.781250\n",
      "Epoch 43 training time: 5.662275\n",
      "Epoch 44 training started ...\n",
      "Epoch 44 completed - train_loss: 90177.695312 , test_loss: 122299.968750\n",
      "Epoch 44 training time: 5.704241\n",
      "Epoch 45 training started ...\n",
      "Epoch 45 completed - train_loss: 90174.318359 , test_loss: 122305.382812\n",
      "Epoch 45 training time: 5.775083\n",
      "Epoch 46 training started ...\n",
      "Epoch 46 completed - train_loss: 90170.594727 , test_loss: 122293.296875\n",
      "Epoch 46 training time: 5.721844\n",
      "Epoch 47 training started ...\n",
      "Epoch 47 completed - train_loss: 90167.534180 , test_loss: 122296.312500\n",
      "Epoch 47 training time: 5.762278\n",
      "Epoch 48 training started ...\n",
      "Epoch 48 completed - train_loss: 90164.324219 , test_loss: 122297.554688\n",
      "Epoch 48 training time: 5.814074\n",
      "Epoch 49 training started ...\n",
      "Epoch 49 completed - train_loss: 90160.660156 , test_loss: 122274.828125\n",
      "Epoch 49 training time: 5.712342\n",
      "Epoch 50 training started ...\n",
      "Epoch 50 completed - train_loss: 90158.641602 , test_loss: 122281.781250\n",
      "Epoch 50 training time: 5.661252\n",
      "Epoch 51 training started ...\n",
      "Epoch 51 completed - train_loss: 90155.360352 , test_loss: 122290.187500\n",
      "Epoch 51 training time: 5.637263\n",
      "Epoch 52 training started ...\n",
      "Epoch 52 completed - train_loss: 90151.876953 , test_loss: 122272.804688\n",
      "Epoch 52 training time: 5.667806\n",
      "Epoch 53 training started ...\n",
      "Epoch 53 completed - train_loss: 90149.304688 , test_loss: 122266.039062\n",
      "Epoch 53 training time: 5.703710\n",
      "Epoch 54 training started ...\n",
      "Epoch 54 completed - train_loss: 90146.735352 , test_loss: 122266.164062\n",
      "Epoch 54 training time: 5.710579\n",
      "Epoch 55 training started ...\n",
      "Epoch 55 completed - train_loss: 90144.052734 , test_loss: 122267.289062\n",
      "Epoch 55 training time: 5.704966\n",
      "Epoch 56 training started ...\n",
      "Epoch 56 completed - train_loss: 90141.191406 , test_loss: 122265.523438\n",
      "Epoch 56 training time: 5.705787\n",
      "Epoch 57 training started ...\n",
      "Epoch 57 completed - train_loss: 90138.454102 , test_loss: 122259.734375\n",
      "Epoch 57 training time: 5.668983\n",
      "Epoch 58 training started ...\n",
      "Epoch 58 completed - train_loss: 90136.108398 , test_loss: 122256.296875\n",
      "Epoch 58 training time: 5.647080\n",
      "Epoch 59 training started ...\n",
      "Epoch 59 completed - train_loss: 90133.040039 , test_loss: 122249.250000\n",
      "Epoch 59 training time: 5.656879\n",
      "Epoch 60 training started ...\n",
      "Epoch 60 completed - train_loss: 90131.018555 , test_loss: 122247.179688\n",
      "Epoch 60 training time: 5.715714\n",
      "Epoch 61 training started ...\n",
      "Epoch 61 completed - train_loss: 90128.343750 , test_loss: 122243.539062\n",
      "Epoch 61 training time: 5.649799\n",
      "Epoch 62 training started ...\n",
      "Epoch 62 completed - train_loss: 90126.124023 , test_loss: 122239.054688\n",
      "Epoch 62 training time: 5.704775\n",
      "Epoch 63 training started ...\n",
      "Epoch 63 completed - train_loss: 90123.989258 , test_loss: 122235.867188\n",
      "Epoch 63 training time: 5.682716\n",
      "Epoch 64 training started ...\n",
      "Epoch 64 completed - train_loss: 90121.896484 , test_loss: 122232.460938\n",
      "Epoch 64 training time: 5.712194\n",
      "Epoch 65 training started ...\n",
      "Epoch 65 completed - train_loss: 90119.866211 , test_loss: 122228.125000\n",
      "Epoch 65 training time: 5.719074\n",
      "Epoch 66 training started ...\n",
      "Epoch 66 completed - train_loss: 90117.979492 , test_loss: 122223.601562\n",
      "Epoch 66 training time: 5.712200\n",
      "Epoch 67 training started ...\n",
      "Epoch 67 completed - train_loss: 90116.161133 , test_loss: 122220.054688\n",
      "Epoch 67 training time: 5.718710\n",
      "Epoch 68 training started ...\n",
      "Epoch 68 completed - train_loss: 90114.377930 , test_loss: 122217.062500\n",
      "Epoch 68 training time: 5.695132\n",
      "Epoch 69 training started ...\n",
      "Epoch 69 completed - train_loss: 90112.642578 , test_loss: 122214.179688\n",
      "Epoch 69 training time: 5.715225\n",
      "Epoch 70 training started ...\n",
      "Epoch 70 completed - train_loss: 90110.982422 , test_loss: 122211.570312\n",
      "Epoch 70 training time: 5.723129\n",
      "Epoch 71 training started ...\n",
      "Epoch 71 completed - train_loss: 90109.373047 , test_loss: 122208.781250\n",
      "Epoch 71 training time: 5.691034\n",
      "Epoch 72 training started ...\n",
      "Epoch 72 completed - train_loss: 90107.854492 , test_loss: 122206.359375\n",
      "Epoch 72 training time: 5.837908\n",
      "Epoch 73 training started ...\n",
      "Epoch 73 completed - train_loss: 90106.387695 , test_loss: 122204.273438\n",
      "Epoch 73 training time: 5.756741\n",
      "Epoch 74 training started ...\n",
      "Epoch 74 completed - train_loss: 90104.962891 , test_loss: 122202.148438\n",
      "Epoch 74 training time: 5.693447\n",
      "Epoch 75 training started ...\n",
      "Epoch 75 completed - train_loss: 90103.616211 , test_loss: 122199.929688\n",
      "Epoch 75 training time: 5.705307\n",
      "Epoch 76 training started ...\n",
      "Epoch 76 completed - train_loss: 90102.340820 , test_loss: 122197.921875\n",
      "Epoch 76 training time: 5.701082\n",
      "Epoch 77 training started ...\n",
      "Epoch 77 completed - train_loss: 90101.129883 , test_loss: 122196.281250\n",
      "Epoch 77 training time: 5.721801\n",
      "Epoch 78 training started ...\n",
      "Epoch 78 completed - train_loss: 90099.974609 , test_loss: 122194.875000\n",
      "Epoch 78 training time: 5.698060\n",
      "Epoch 79 training started ...\n",
      "Epoch 79 completed - train_loss: 90098.877930 , test_loss: 122193.406250\n",
      "Epoch 79 training time: 5.690367\n",
      "Epoch 80 training started ...\n",
      "Epoch 80 completed - train_loss: 90097.862305 , test_loss: 122191.867188\n",
      "Epoch 80 training time: 5.703629\n",
      "Epoch 81 training started ...\n",
      "Epoch 81 completed - train_loss: 90096.918945 , test_loss: 122190.351562\n",
      "Epoch 81 training time: 5.723938\n",
      "Epoch 82 training started ...\n",
      "Epoch 82 completed - train_loss: 90096.035156 , test_loss: 122188.976562\n",
      "Epoch 82 training time: 5.740214\n",
      "Epoch 83 training started ...\n",
      "Epoch 83 completed - train_loss: 90095.210938 , test_loss: 122187.828125\n",
      "Epoch 83 training time: 5.718036\n",
      "Epoch 84 training started ...\n",
      "Epoch 84 completed - train_loss: 90094.444336 , test_loss: 122186.906250\n",
      "Epoch 84 training time: 5.688682\n",
      "Epoch 85 training started ...\n",
      "Epoch 85 completed - train_loss: 90093.722656 , test_loss: 122186.132812\n",
      "Epoch 85 training time: 5.661645\n",
      "Epoch 86 training started ...\n",
      "Epoch 86 completed - train_loss: 90093.055664 , test_loss: 122185.437500\n",
      "Epoch 86 training time: 5.739760\n",
      "Epoch 87 training started ...\n",
      "Epoch 87 completed - train_loss: 90092.438477 , test_loss: 122184.781250\n",
      "Epoch 87 training time: 5.720057\n",
      "Epoch 88 training started ...\n",
      "Epoch 88 completed - train_loss: 90091.875977 , test_loss: 122184.109375\n",
      "Epoch 88 training time: 5.719052\n",
      "Epoch 89 training started ...\n",
      "Epoch 89 completed - train_loss: 90091.359375 , test_loss: 122183.468750\n",
      "Epoch 89 training time: 5.724225\n",
      "Epoch 90 training started ...\n",
      "Epoch 90 completed - train_loss: 90090.893555 , test_loss: 122182.843750\n",
      "Epoch 90 training time: 5.728958\n",
      "Epoch 91 training started ...\n",
      "Epoch 91 completed - train_loss: 90090.484375 , test_loss: 122182.250000\n",
      "Epoch 91 training time: 5.684759\n",
      "Epoch 92 training started ...\n",
      "Epoch 92 completed - train_loss: 90090.117188 , test_loss: 122181.750000\n",
      "Epoch 92 training time: 5.659127\n",
      "Epoch 93 training started ...\n",
      "Epoch 93 completed - train_loss: 90089.793945 , test_loss: 122181.296875\n",
      "Epoch 93 training time: 5.651919\n",
      "Epoch 94 training started ...\n",
      "Epoch 94 completed - train_loss: 90089.521484 , test_loss: 122180.929688\n",
      "Epoch 94 training time: 5.667358\n",
      "Epoch 95 training started ...\n",
      "Epoch 95 completed - train_loss: 90089.291992 , test_loss: 122180.640625\n",
      "Epoch 95 training time: 5.675382\n",
      "Epoch 96 training started ...\n",
      "Epoch 96 completed - train_loss: 90089.102539 , test_loss: 122180.421875\n",
      "Epoch 96 training time: 5.736213\n",
      "Epoch 97 training started ...\n",
      "Epoch 97 completed - train_loss: 90088.954102 , test_loss: 122180.257812\n",
      "Epoch 97 training time: 5.746042\n",
      "Epoch 98 training started ...\n",
      "Epoch 98 completed - train_loss: 90088.844727 , test_loss: 122180.148438\n",
      "Epoch 98 training time: 5.773892\n",
      "Epoch 99 training started ...\n",
      "Epoch 99 completed - train_loss: 90088.772461 , test_loss: 122180.093750\n",
      "Epoch 99 training time: 5.834531\n",
      "Epoch 0 training started ...\n",
      "Epoch 0 completed - train_loss: 191313.548828 , test_loss: 278937.875000\n",
      "Epoch 0 training time: 5.888391\n",
      "Epoch 1 training started ...\n",
      "Epoch 1 completed - train_loss: 180729.929688 , test_loss: 250032.390625\n",
      "Epoch 1 training time: 5.885489\n",
      "Epoch 2 training started ...\n",
      "Epoch 2 completed - train_loss: 146744.541016 , test_loss: 250748.343750\n",
      "Epoch 2 training time: 5.757329\n",
      "Epoch 3 training started ...\n",
      "Epoch 3 completed - train_loss: 151761.566406 , test_loss: 219313.390625\n",
      "Epoch 3 training time: 5.665383\n",
      "Epoch 4 training started ...\n",
      "Epoch 4 completed - train_loss: 146132.484375 , test_loss: 228114.500000\n",
      "Epoch 4 training time: 5.688007\n",
      "Epoch 5 training started ...\n",
      "Epoch 5 completed - train_loss: 136916.873047 , test_loss: 229754.375000\n",
      "Epoch 5 training time: 5.742321\n",
      "Epoch 6 training started ...\n",
      "Epoch 6 completed - train_loss: 135599.039062 , test_loss: 229649.109375\n",
      "Epoch 6 training time: 5.704719\n",
      "Epoch 7 training started ...\n",
      "Epoch 7 completed - train_loss: 142725.896484 , test_loss: 201446.375000\n",
      "Epoch 7 training time: 5.702179\n",
      "Epoch 8 training started ...\n",
      "Epoch 8 completed - train_loss: 135984.650391 , test_loss: 214472.062500\n",
      "Epoch 8 training time: 5.703026\n",
      "Epoch 9 training started ...\n",
      "Epoch 9 completed - train_loss: 136981.007812 , test_loss: 205272.078125\n",
      "Epoch 9 training time: 5.761882\n",
      "Epoch 10 training started ...\n",
      "Epoch 10 completed - train_loss: 128528.557617 , test_loss: 208896.953125\n",
      "Epoch 10 training time: 5.675405\n",
      "Epoch 11 training started ...\n",
      "Epoch 11 completed - train_loss: 127070.464844 , test_loss: 205047.453125\n",
      "Epoch 11 training time: 5.669908\n",
      "Epoch 12 training started ...\n",
      "Epoch 12 completed - train_loss: 125024.263672 , test_loss: 208198.406250\n",
      "Epoch 12 training time: 5.675754\n",
      "Epoch 13 training started ...\n",
      "Epoch 13 completed - train_loss: 128029.130859 , test_loss: 210030.437500\n",
      "Epoch 13 training time: 5.675793\n",
      "Epoch 14 training started ...\n",
      "Epoch 14 completed - train_loss: 125552.342773 , test_loss: 211127.718750\n",
      "Epoch 14 training time: 5.679863\n",
      "Epoch 15 training started ...\n",
      "Epoch 15 completed - train_loss: 127600.912109 , test_loss: 204995.234375\n",
      "Epoch 15 training time: 5.687068\n",
      "Epoch 16 training started ...\n",
      "Epoch 16 completed - train_loss: 124409.670898 , test_loss: 201201.250000\n",
      "Epoch 16 training time: 5.678931\n",
      "Epoch 17 training started ...\n",
      "Epoch 17 completed - train_loss: 126119.556641 , test_loss: 213137.671875\n",
      "Epoch 17 training time: 5.663985\n",
      "Epoch 18 training started ...\n",
      "Epoch 18 completed - train_loss: 129838.764648 , test_loss: 220613.718750\n",
      "Epoch 18 training time: 5.675249\n",
      "Epoch 19 training started ...\n",
      "Epoch 19 completed - train_loss: 130336.615234 , test_loss: 208369.859375\n",
      "Epoch 19 training time: 5.676923\n",
      "Epoch 20 training started ...\n",
      "Epoch 20 completed - train_loss: 126010.278320 , test_loss: 204644.250000\n",
      "Epoch 20 training time: 5.669382\n",
      "Epoch 21 training started ...\n",
      "Epoch 21 completed - train_loss: 125125.905273 , test_loss: 201902.750000\n",
      "Epoch 21 training time: 5.665109\n",
      "Epoch 22 training started ...\n",
      "Epoch 22 completed - train_loss: 123880.364258 , test_loss: 206151.265625\n",
      "Epoch 22 training time: 5.695045\n",
      "Epoch 23 training started ...\n",
      "Epoch 23 completed - train_loss: 126184.984375 , test_loss: 202432.859375\n",
      "Epoch 23 training time: 5.666195\n",
      "Epoch 24 training started ...\n",
      "Epoch 24 completed - train_loss: 124477.378906 , test_loss: 201238.875000\n",
      "Epoch 24 training time: 5.746356\n",
      "Epoch 25 training started ...\n",
      "Epoch 25 completed - train_loss: 125791.660156 , test_loss: 202365.296875\n",
      "Epoch 25 training time: 5.723112\n",
      "Epoch 26 training started ...\n",
      "Epoch 26 completed - train_loss: 123597.830078 , test_loss: 204219.250000\n",
      "Epoch 26 training time: 5.731257\n",
      "Epoch 27 training started ...\n",
      "Epoch 27 completed - train_loss: 123075.189453 , test_loss: 201332.156250\n",
      "Epoch 27 training time: 5.719862\n",
      "Epoch 28 training started ...\n",
      "Epoch 28 completed - train_loss: 122743.770508 , test_loss: 201181.687500\n",
      "Epoch 28 training time: 5.715706\n",
      "Epoch 29 training started ...\n",
      "Epoch 29 completed - train_loss: 122780.184570 , test_loss: 201615.140625\n",
      "Epoch 29 training time: 5.712996\n",
      "Epoch 30 training started ...\n",
      "Epoch 30 completed - train_loss: 122727.913086 , test_loss: 201741.750000\n",
      "Epoch 30 training time: 5.691314\n",
      "Epoch 31 training started ...\n",
      "Epoch 31 completed - train_loss: 123611.696289 , test_loss: 201427.109375\n",
      "Epoch 31 training time: 5.683019\n",
      "Epoch 32 training started ...\n",
      "Epoch 32 completed - train_loss: 122891.277344 , test_loss: 202392.281250\n",
      "Epoch 32 training time: 5.696453\n",
      "Epoch 33 training started ...\n",
      "Epoch 33 completed - train_loss: 123297.212891 , test_loss: 204689.468750\n",
      "Epoch 33 training time: 5.705691\n",
      "Epoch 34 training started ...\n",
      "Epoch 34 completed - train_loss: 125138.870117 , test_loss: 205346.625000\n",
      "Epoch 34 training time: 5.700673\n",
      "Epoch 35 training started ...\n",
      "Epoch 35 completed - train_loss: 123687.974609 , test_loss: 207292.187500\n",
      "Epoch 35 training time: 5.696869\n",
      "Epoch 36 training started ...\n",
      "Epoch 36 completed - train_loss: 124786.981445 , test_loss: 201565.218750\n",
      "Epoch 36 training time: 5.691590\n",
      "Epoch 37 training started ...\n",
      "Epoch 37 completed - train_loss: 123232.744141 , test_loss: 202557.031250\n",
      "Epoch 37 training time: 5.703695\n",
      "Epoch 38 training started ...\n",
      "Epoch 38 completed - train_loss: 124144.047852 , test_loss: 201856.437500\n",
      "Epoch 38 training time: 5.711285\n",
      "Epoch 39 training started ...\n",
      "Epoch 39 completed - train_loss: 123119.190430 , test_loss: 200534.812500\n",
      "Epoch 39 training time: 5.700126\n",
      "Epoch 40 training started ...\n",
      "Epoch 40 completed - train_loss: 122515.679688 , test_loss: 200976.234375\n",
      "Epoch 40 training time: 5.666768\n",
      "Epoch 41 training started ...\n",
      "Epoch 41 completed - train_loss: 122462.156250 , test_loss: 201579.968750\n",
      "Epoch 41 training time: 5.681846\n",
      "Epoch 42 training started ...\n",
      "Epoch 42 completed - train_loss: 123116.948242 , test_loss: 201525.390625\n",
      "Epoch 42 training time: 5.691209\n",
      "Epoch 43 training started ...\n",
      "Epoch 43 completed - train_loss: 122422.390625 , test_loss: 201044.093750\n",
      "Epoch 43 training time: 5.691238\n",
      "Epoch 44 training started ...\n",
      "Epoch 44 completed - train_loss: 122965.447266 , test_loss: 202186.875000\n",
      "Epoch 44 training time: 5.674228\n",
      "Epoch 45 training started ...\n",
      "Epoch 45 completed - train_loss: 123048.013672 , test_loss: 201233.718750\n",
      "Epoch 45 training time: 5.670797\n",
      "Epoch 46 training started ...\n",
      "Epoch 46 completed - train_loss: 122488.458984 , test_loss: 201027.171875\n",
      "Epoch 46 training time: 5.669162\n",
      "Epoch 47 training started ...\n",
      "Epoch 47 completed - train_loss: 123065.906250 , test_loss: 201820.328125\n",
      "Epoch 47 training time: 5.686967\n",
      "Epoch 48 training started ...\n",
      "Epoch 48 completed - train_loss: 122432.861328 , test_loss: 200779.812500\n",
      "Epoch 48 training time: 5.683550\n",
      "Epoch 49 training started ...\n",
      "Epoch 49 completed - train_loss: 122573.511719 , test_loss: 203881.906250\n",
      "Epoch 49 training time: 5.668274\n",
      "Epoch 50 training started ...\n",
      "Epoch 50 completed - train_loss: 123797.174805 , test_loss: 201790.390625\n",
      "Epoch 50 training time: 5.676785\n",
      "Epoch 51 training started ...\n",
      "Epoch 51 completed - train_loss: 122683.494141 , test_loss: 200815.671875\n",
      "Epoch 51 training time: 5.695128\n",
      "Epoch 52 training started ...\n",
      "Epoch 52 completed - train_loss: 122350.298828 , test_loss: 202185.796875\n",
      "Epoch 52 training time: 5.688767\n",
      "Epoch 53 training started ...\n",
      "Epoch 53 completed - train_loss: 123001.888672 , test_loss: 201179.593750\n",
      "Epoch 53 training time: 5.739759\n",
      "Epoch 54 training started ...\n",
      "Epoch 54 completed - train_loss: 122810.914062 , test_loss: 201344.906250\n",
      "Epoch 54 training time: 5.826060\n",
      "Epoch 55 training started ...\n",
      "Epoch 55 completed - train_loss: 122711.117188 , test_loss: 201956.468750\n",
      "Epoch 55 training time: 5.756486\n",
      "Epoch 56 training started ...\n",
      "Epoch 56 completed - train_loss: 122669.887695 , test_loss: 201024.093750\n",
      "Epoch 56 training time: 5.744254\n",
      "Epoch 57 training started ...\n",
      "Epoch 57 completed - train_loss: 122548.751953 , test_loss: 200415.375000\n",
      "Epoch 57 training time: 5.689785\n",
      "Epoch 58 training started ...\n",
      "Epoch 58 completed - train_loss: 122426.229492 , test_loss: 202423.625000\n",
      "Epoch 58 training time: 5.677155\n",
      "Epoch 59 training started ...\n",
      "Epoch 59 completed - train_loss: 123123.613281 , test_loss: 201168.343750\n",
      "Epoch 59 training time: 5.696549\n",
      "Epoch 60 training started ...\n",
      "Epoch 60 completed - train_loss: 122738.818359 , test_loss: 200817.750000\n",
      "Epoch 60 training time: 5.684483\n",
      "Epoch 61 training started ...\n",
      "Epoch 61 completed - train_loss: 122869.806641 , test_loss: 202012.687500\n",
      "Epoch 61 training time: 5.746441\n",
      "Epoch 62 training started ...\n",
      "Epoch 62 completed - train_loss: 123102.892578 , test_loss: 202728.218750\n",
      "Epoch 62 training time: 5.710680\n",
      "Epoch 63 training started ...\n",
      "Epoch 63 completed - train_loss: 123065.640625 , test_loss: 200871.250000\n",
      "Epoch 63 training time: 5.716088\n",
      "Epoch 64 training started ...\n",
      "Epoch 64 completed - train_loss: 122278.865234 , test_loss: 200841.453125\n",
      "Epoch 64 training time: 5.766240\n",
      "Epoch 65 training started ...\n",
      "Epoch 65 completed - train_loss: 122245.923828 , test_loss: 200677.828125\n",
      "Epoch 65 training time: 5.840354\n",
      "Epoch 66 training started ...\n",
      "Epoch 66 completed - train_loss: 122271.163086 , test_loss: 201398.625000\n",
      "Epoch 66 training time: 5.751595\n",
      "Epoch 67 training started ...\n",
      "Epoch 67 completed - train_loss: 122313.248047 , test_loss: 200819.046875\n",
      "Epoch 67 training time: 5.743463\n",
      "Epoch 68 training started ...\n",
      "Epoch 68 completed - train_loss: 122147.658203 , test_loss: 200696.703125\n",
      "Epoch 68 training time: 5.652318\n",
      "Epoch 69 training started ...\n",
      "Epoch 69 completed - train_loss: 122068.757812 , test_loss: 200719.656250\n",
      "Epoch 69 training time: 5.614846\n",
      "Epoch 70 training started ...\n",
      "Epoch 70 completed - train_loss: 122159.193359 , test_loss: 200642.265625\n",
      "Epoch 70 training time: 5.635577\n",
      "Epoch 71 training started ...\n",
      "Epoch 71 completed - train_loss: 122252.605469 , test_loss: 201051.984375\n",
      "Epoch 71 training time: 5.676345\n",
      "Epoch 72 training started ...\n",
      "Epoch 72 completed - train_loss: 122550.229492 , test_loss: 202096.796875\n",
      "Epoch 72 training time: 5.648687\n",
      "Epoch 73 training started ...\n",
      "Epoch 73 completed - train_loss: 122766.088867 , test_loss: 201926.015625\n",
      "Epoch 73 training time: 5.720520\n",
      "Epoch 74 training started ...\n",
      "Epoch 74 completed - train_loss: 122747.823242 , test_loss: 201662.812500\n",
      "Epoch 74 training time: 5.650997\n",
      "Epoch 75 training started ...\n",
      "Epoch 75 completed - train_loss: 122548.792969 , test_loss: 201137.125000\n",
      "Epoch 75 training time: 5.625369\n",
      "Epoch 76 training started ...\n",
      "Epoch 76 completed - train_loss: 122230.758789 , test_loss: 201124.609375\n",
      "Epoch 76 training time: 5.647619\n",
      "Epoch 77 training started ...\n",
      "Epoch 77 completed - train_loss: 122432.938477 , test_loss: 201950.718750\n",
      "Epoch 77 training time: 5.716092\n",
      "Epoch 78 training started ...\n",
      "Epoch 78 completed - train_loss: 122531.384766 , test_loss: 200947.593750\n",
      "Epoch 78 training time: 5.658233\n",
      "Epoch 79 training started ...\n",
      "Epoch 79 completed - train_loss: 122268.984375 , test_loss: 200404.734375\n",
      "Epoch 79 training time: 5.672291\n",
      "Epoch 80 training started ...\n",
      "Epoch 80 completed - train_loss: 121970.153320 , test_loss: 200778.625000\n",
      "Epoch 80 training time: 5.693492\n",
      "Epoch 81 training started ...\n",
      "Epoch 81 completed - train_loss: 122185.311523 , test_loss: 200820.171875\n",
      "Epoch 81 training time: 5.697927\n",
      "Epoch 82 training started ...\n",
      "Epoch 82 completed - train_loss: 121973.293945 , test_loss: 200379.859375\n",
      "Epoch 82 training time: 5.701573\n",
      "Epoch 83 training started ...\n",
      "Epoch 83 completed - train_loss: 121921.397461 , test_loss: 200468.468750\n",
      "Epoch 83 training time: 5.728849\n",
      "Epoch 84 training started ...\n",
      "Epoch 84 completed - train_loss: 121965.209961 , test_loss: 200552.890625\n",
      "Epoch 84 training time: 5.751818\n",
      "Epoch 85 training started ...\n",
      "Epoch 85 completed - train_loss: 121983.427734 , test_loss: 200477.671875\n",
      "Epoch 85 training time: 5.765085\n",
      "Epoch 86 training started ...\n",
      "Epoch 86 completed - train_loss: 121988.955078 , test_loss: 200452.375000\n",
      "Epoch 86 training time: 5.686805\n",
      "Epoch 87 training started ...\n",
      "Epoch 87 completed - train_loss: 121966.839844 , test_loss: 200347.875000\n",
      "Epoch 87 training time: 5.665385\n",
      "Epoch 88 training started ...\n",
      "Epoch 88 completed - train_loss: 121914.650391 , test_loss: 200432.031250\n",
      "Epoch 88 training time: 5.666219\n",
      "Epoch 89 training started ...\n",
      "Epoch 89 completed - train_loss: 121917.142578 , test_loss: 200340.140625\n",
      "Epoch 89 training time: 5.615839\n",
      "Epoch 90 training started ...\n",
      "Epoch 90 completed - train_loss: 121914.080078 , test_loss: 200388.453125\n",
      "Epoch 90 training time: 5.606248\n",
      "Epoch 91 training started ...\n",
      "Epoch 91 completed - train_loss: 121890.250977 , test_loss: 200375.968750\n",
      "Epoch 91 training time: 5.665166\n",
      "Epoch 92 training started ...\n",
      "Epoch 92 completed - train_loss: 121905.501953 , test_loss: 200346.171875\n",
      "Epoch 92 training time: 5.723136\n",
      "Epoch 93 training started ...\n",
      "Epoch 93 completed - train_loss: 121885.000000 , test_loss: 200365.125000\n",
      "Epoch 93 training time: 5.764535\n",
      "Epoch 94 training started ...\n",
      "Epoch 94 completed - train_loss: 121885.133789 , test_loss: 200385.671875\n",
      "Epoch 94 training time: 5.687814\n",
      "Epoch 95 training started ...\n",
      "Epoch 95 completed - train_loss: 121892.810547 , test_loss: 200353.125000\n",
      "Epoch 95 training time: 5.712993\n",
      "Epoch 96 training started ...\n",
      "Epoch 96 completed - train_loss: 121871.076172 , test_loss: 200352.031250\n",
      "Epoch 96 training time: 5.764451\n",
      "Epoch 97 training started ...\n",
      "Epoch 97 completed - train_loss: 121867.624023 , test_loss: 200347.734375\n",
      "Epoch 97 training time: 5.667753\n",
      "Epoch 98 training started ...\n",
      "Epoch 98 completed - train_loss: 121869.401367 , test_loss: 200327.875000\n",
      "Epoch 98 training time: 5.670658\n",
      "Epoch 99 training started ...\n",
      "Epoch 99 completed - train_loss: 121863.166016 , test_loss: 200333.062500\n",
      "Epoch 99 training time: 5.677645\n",
      "Epoch 0 training started ...\n",
      "Epoch 0 completed - train_loss: 562806.882812 , test_loss: 782108.750000\n",
      "Epoch 0 training time: 5.671720\n",
      "Epoch 1 training started ...\n",
      "Epoch 1 completed - train_loss: 555359.960938 , test_loss: 760199.875000\n",
      "Epoch 1 training time: 5.740817\n",
      "Epoch 2 training started ...\n",
      "Epoch 2 completed - train_loss: 533954.570312 , test_loss: 718942.187500\n",
      "Epoch 2 training time: 5.755604\n",
      "Epoch 3 training started ...\n",
      "Epoch 3 completed - train_loss: 500241.882812 , test_loss: 664823.125000\n",
      "Epoch 3 training time: 5.727136\n",
      "Epoch 4 training started ...\n",
      "Epoch 4 completed - train_loss: 458946.542969 , test_loss: 602139.500000\n",
      "Epoch 4 training time: 5.664688\n",
      "Epoch 5 training started ...\n",
      "Epoch 5 completed - train_loss: 409313.089844 , test_loss: 516635.687500\n",
      "Epoch 5 training time: 5.679999\n",
      "Epoch 6 training started ...\n",
      "Epoch 6 completed - train_loss: 331615.759766 , test_loss: 364788.250000\n",
      "Epoch 6 training time: 5.701329\n",
      "Epoch 7 training started ...\n",
      "Epoch 7 completed - train_loss: 205831.070312 , test_loss: 138374.734375\n",
      "Epoch 7 training time: 5.650181\n",
      "Epoch 8 training started ...\n",
      "Epoch 8 completed - train_loss: 63742.579590 , test_loss: 53297.609375\n",
      "Epoch 8 training time: 5.616252\n",
      "Epoch 9 training started ...\n",
      "Epoch 9 completed - train_loss: 24972.305176 , test_loss: 24337.570312\n",
      "Epoch 9 training time: 5.630330\n",
      "Epoch 10 training started ...\n",
      "Epoch 10 completed - train_loss: 15182.045776 , test_loss: 11640.816406\n",
      "Epoch 10 training time: 5.695863\n",
      "Epoch 11 training started ...\n",
      "Epoch 11 completed - train_loss: 11298.866455 , test_loss: 12509.003906\n",
      "Epoch 11 training time: 5.684231\n",
      "Epoch 12 training started ...\n",
      "Epoch 12 completed - train_loss: 10804.047791 , test_loss: 14959.058594\n",
      "Epoch 12 training time: 5.699457\n",
      "Epoch 13 training started ...\n",
      "Epoch 13 completed - train_loss: 10626.160095 , test_loss: 12512.972656\n",
      "Epoch 13 training time: 5.615716\n",
      "Epoch 14 training started ...\n",
      "Epoch 14 completed - train_loss: 10347.171082 , test_loss: 12671.775391\n",
      "Epoch 14 training time: 5.668750\n",
      "Epoch 15 training started ...\n",
      "Epoch 15 completed - train_loss: 10029.267273 , test_loss: 11143.746094\n",
      "Epoch 15 training time: 5.710650\n",
      "Epoch 16 training started ...\n",
      "Epoch 16 completed - train_loss: 9856.470032 , test_loss: 11573.422852\n",
      "Epoch 16 training time: 5.720453\n",
      "Epoch 17 training started ...\n",
      "Epoch 17 completed - train_loss: 9802.026489 , test_loss: 11113.929688\n",
      "Epoch 17 training time: 5.671089\n",
      "Epoch 18 training started ...\n",
      "Epoch 18 completed - train_loss: 9751.437134 , test_loss: 11255.279297\n",
      "Epoch 18 training time: 5.684911\n",
      "Epoch 19 training started ...\n",
      "Epoch 19 completed - train_loss: 9740.369202 , test_loss: 11071.492188\n",
      "Epoch 19 training time: 5.657579\n",
      "Epoch 20 training started ...\n",
      "Epoch 20 completed - train_loss: 9722.336243 , test_loss: 11070.413086\n",
      "Epoch 20 training time: 5.713076\n",
      "Epoch 21 training started ...\n",
      "Epoch 21 completed - train_loss: 9702.825562 , test_loss: 11094.106445\n",
      "Epoch 21 training time: 5.675127\n",
      "Epoch 22 training started ...\n",
      "Epoch 22 completed - train_loss: 9690.619690 , test_loss: 11071.408203\n",
      "Epoch 22 training time: 5.672415\n",
      "Epoch 23 training started ...\n",
      "Epoch 23 completed - train_loss: 9680.398621 , test_loss: 11046.803711\n",
      "Epoch 23 training time: 5.683512\n",
      "Epoch 24 training started ...\n",
      "Epoch 24 completed - train_loss: 9669.230774 , test_loss: 11032.898438\n",
      "Epoch 24 training time: 5.694953\n",
      "Epoch 25 training started ...\n",
      "Epoch 25 completed - train_loss: 9658.079407 , test_loss: 11048.253906\n",
      "Epoch 25 training time: 5.702681\n",
      "Epoch 26 training started ...\n",
      "Epoch 26 completed - train_loss: 9652.308167 , test_loss: 10988.693359\n",
      "Epoch 26 training time: 5.692952\n",
      "Epoch 27 training started ...\n",
      "Epoch 27 completed - train_loss: 9638.628967 , test_loss: 11028.516602\n",
      "Epoch 27 training time: 5.690556\n",
      "Epoch 28 training started ...\n",
      "Epoch 28 completed - train_loss: 9632.721802 , test_loss: 10975.115234\n",
      "Epoch 28 training time: 5.687917\n",
      "Epoch 29 training started ...\n",
      "Epoch 29 completed - train_loss: 9618.103760 , test_loss: 10986.833984\n",
      "Epoch 29 training time: 5.686070\n",
      "Epoch 30 training started ...\n",
      "Epoch 30 completed - train_loss: 9608.257812 , test_loss: 10976.591797\n",
      "Epoch 30 training time: 5.686327\n",
      "Epoch 31 training started ...\n",
      "Epoch 31 completed - train_loss: 9601.464539 , test_loss: 10946.380859\n",
      "Epoch 31 training time: 5.702101\n",
      "Epoch 32 training started ...\n",
      "Epoch 32 completed - train_loss: 9592.375244 , test_loss: 10929.730469\n",
      "Epoch 32 training time: 5.675227\n",
      "Epoch 33 training started ...\n",
      "Epoch 33 completed - train_loss: 9581.611389 , test_loss: 10935.826172\n",
      "Epoch 33 training time: 5.695189\n",
      "Epoch 34 training started ...\n",
      "Epoch 34 completed - train_loss: 9572.782227 , test_loss: 10926.353516\n",
      "Epoch 34 training time: 5.681572\n",
      "Epoch 35 training started ...\n",
      "Epoch 35 completed - train_loss: 9566.461975 , test_loss: 10897.990234\n",
      "Epoch 35 training time: 5.665699\n",
      "Epoch 36 training started ...\n",
      "Epoch 36 completed - train_loss: 9558.055969 , test_loss: 10882.412109\n",
      "Epoch 36 training time: 5.657486\n",
      "Epoch 37 training started ...\n",
      "Epoch 37 completed - train_loss: 9548.173706 , test_loss: 10888.990234\n",
      "Epoch 37 training time: 5.718095\n",
      "Epoch 38 training started ...\n",
      "Epoch 38 completed - train_loss: 9539.963196 , test_loss: 10880.930664\n",
      "Epoch 38 training time: 5.671036\n",
      "Epoch 39 training started ...\n",
      "Epoch 39 completed - train_loss: 9534.238831 , test_loss: 10854.357422\n",
      "Epoch 39 training time: 5.682244\n",
      "Epoch 40 training started ...\n",
      "Epoch 40 completed - train_loss: 9526.513611 , test_loss: 10839.279297\n",
      "Epoch 40 training time: 5.684364\n",
      "Epoch 41 training started ...\n",
      "Epoch 41 completed - train_loss: 9517.461304 , test_loss: 10844.789062\n",
      "Epoch 41 training time: 5.676123\n",
      "Epoch 42 training started ...\n",
      "Epoch 42 completed - train_loss: 9510.008850 , test_loss: 10837.388672\n",
      "Epoch 42 training time: 5.673582\n",
      "Epoch 43 training started ...\n",
      "Epoch 43 completed - train_loss: 9504.601624 , test_loss: 10812.927734\n",
      "Epoch 43 training time: 5.672464\n",
      "Epoch 44 training started ...\n",
      "Epoch 44 completed - train_loss: 9497.572327 , test_loss: 10798.791016\n",
      "Epoch 44 training time: 5.667573\n",
      "Epoch 45 training started ...\n",
      "Epoch 45 completed - train_loss: 9489.056335 , test_loss: 10822.016602\n",
      "Epoch 45 training time: 5.675302\n",
      "Epoch 46 training started ...\n",
      "Epoch 46 completed - train_loss: 9488.015198 , test_loss: 10758.886719\n",
      "Epoch 46 training time: 5.663947\n",
      "Epoch 47 training started ...\n",
      "Epoch 47 completed - train_loss: 9480.428772 , test_loss: 10777.012695\n",
      "Epoch 47 training time: 5.676459\n",
      "Epoch 48 training started ...\n",
      "Epoch 48 completed - train_loss: 9472.338684 , test_loss: 10756.415039\n",
      "Epoch 48 training time: 5.663721\n",
      "Epoch 49 training started ...\n",
      "Epoch 49 completed - train_loss: 9465.816162 , test_loss: 10770.374023\n",
      "Epoch 49 training time: 5.675260\n",
      "Epoch 50 training started ...\n",
      "Epoch 50 completed - train_loss: 9461.788513 , test_loss: 10745.242188\n",
      "Epoch 50 training time: 5.686333\n",
      "Epoch 51 training started ...\n",
      "Epoch 51 completed - train_loss: 9453.759155 , test_loss: 10754.850586\n",
      "Epoch 51 training time: 5.700431\n",
      "Epoch 52 training started ...\n",
      "Epoch 52 completed - train_loss: 9447.400513 , test_loss: 10742.500000\n",
      "Epoch 52 training time: 5.748027\n",
      "Epoch 53 training started ...\n",
      "Epoch 53 completed - train_loss: 9442.758728 , test_loss: 10726.998047\n",
      "Epoch 53 training time: 5.689175\n",
      "Epoch 54 training started ...\n",
      "Epoch 54 completed - train_loss: 9436.378357 , test_loss: 10732.927734\n",
      "Epoch 54 training time: 5.659848\n",
      "Epoch 55 training started ...\n",
      "Epoch 55 completed - train_loss: 9430.674133 , test_loss: 10732.326172\n",
      "Epoch 55 training time: 5.668311\n",
      "Epoch 56 training started ...\n",
      "Epoch 56 completed - train_loss: 9429.736816 , test_loss: 10693.718750\n",
      "Epoch 56 training time: 5.678930\n",
      "Epoch 57 training started ...\n",
      "Epoch 57 completed - train_loss: 9423.904053 , test_loss: 10710.361328\n",
      "Epoch 57 training time: 5.664618\n",
      "Epoch 58 training started ...\n",
      "Epoch 58 completed - train_loss: 9419.765015 , test_loss: 10695.360352\n",
      "Epoch 58 training time: 5.676401\n",
      "Epoch 59 training started ...\n",
      "Epoch 59 completed - train_loss: 9413.113159 , test_loss: 10705.345703\n",
      "Epoch 59 training time: 5.673568\n",
      "Epoch 60 training started ...\n",
      "Epoch 60 completed - train_loss: 9411.064819 , test_loss: 10678.335938\n",
      "Epoch 60 training time: 5.681946\n",
      "Epoch 61 training started ...\n",
      "Epoch 61 completed - train_loss: 9404.945190 , test_loss: 10696.464844\n",
      "Epoch 61 training time: 5.666133\n",
      "Epoch 62 training started ...\n",
      "Epoch 62 completed - train_loss: 9403.738708 , test_loss: 10666.248047\n",
      "Epoch 62 training time: 5.672188\n",
      "Epoch 63 training started ...\n",
      "Epoch 63 completed - train_loss: 9398.427734 , test_loss: 10683.792969\n",
      "Epoch 63 training time: 5.670221\n",
      "Epoch 64 training started ...\n",
      "Epoch 64 completed - train_loss: 9395.635681 , test_loss: 10668.391602\n",
      "Epoch 64 training time: 5.683185\n",
      "Epoch 65 training started ...\n",
      "Epoch 65 completed - train_loss: 9391.111511 , test_loss: 10663.588867\n",
      "Epoch 65 training time: 5.673830\n",
      "Epoch 66 training started ...\n",
      "Epoch 66 completed - train_loss: 9387.553284 , test_loss: 10670.023438\n",
      "Epoch 66 training time: 5.672308\n",
      "Epoch 67 training started ...\n",
      "Epoch 67 completed - train_loss: 9385.599915 , test_loss: 10657.960938\n",
      "Epoch 67 training time: 5.688503\n",
      "Epoch 68 training started ...\n",
      "Epoch 68 completed - train_loss: 9382.539001 , test_loss: 10654.700195\n",
      "Epoch 68 training time: 5.669577\n",
      "Epoch 69 training started ...\n",
      "Epoch 69 completed - train_loss: 9379.121399 , test_loss: 10656.806641\n",
      "Epoch 69 training time: 5.712455\n",
      "Epoch 70 training started ...\n",
      "Epoch 70 completed - train_loss: 9377.362427 , test_loss: 10648.318359\n",
      "Epoch 70 training time: 5.665634\n",
      "Epoch 71 training started ...\n",
      "Epoch 71 completed - train_loss: 9374.848145 , test_loss: 10643.564453\n",
      "Epoch 71 training time: 5.681024\n",
      "Epoch 72 training started ...\n",
      "Epoch 72 completed - train_loss: 9372.635071 , test_loss: 10640.065430\n",
      "Epoch 72 training time: 5.672473\n",
      "Epoch 73 training started ...\n",
      "Epoch 73 completed - train_loss: 9370.107178 , test_loss: 10641.990234\n",
      "Epoch 73 training time: 5.701777\n",
      "Epoch 74 training started ...\n",
      "Epoch 74 completed - train_loss: 9367.995544 , test_loss: 10638.051758\n",
      "Epoch 74 training time: 5.697081\n",
      "Epoch 75 training started ...\n",
      "Epoch 75 completed - train_loss: 9366.238586 , test_loss: 10637.277344\n",
      "Epoch 75 training time: 5.710138\n",
      "Epoch 76 training started ...\n",
      "Epoch 76 completed - train_loss: 9364.880859 , test_loss: 10632.047852\n",
      "Epoch 76 training time: 5.697591\n",
      "Epoch 77 training started ...\n",
      "Epoch 77 completed - train_loss: 9363.340210 , test_loss: 10630.375000\n",
      "Epoch 77 training time: 5.694151\n",
      "Epoch 78 training started ...\n",
      "Epoch 78 completed - train_loss: 9361.406067 , test_loss: 10630.982422\n",
      "Epoch 78 training time: 5.698317\n",
      "Epoch 79 training started ...\n",
      "Epoch 79 completed - train_loss: 9360.423035 , test_loss: 10626.082031\n",
      "Epoch 79 training time: 5.694236\n",
      "Epoch 80 training started ...\n",
      "Epoch 80 completed - train_loss: 9359.086487 , test_loss: 10625.127930\n",
      "Epoch 80 training time: 5.700481\n",
      "Epoch 81 training started ...\n",
      "Epoch 81 completed - train_loss: 9357.593689 , test_loss: 10625.772461\n",
      "Epoch 81 training time: 5.706210\n",
      "Epoch 82 training started ...\n",
      "Epoch 82 completed - train_loss: 9356.859375 , test_loss: 10621.841797\n",
      "Epoch 82 training time: 5.720207\n",
      "Epoch 83 training started ...\n",
      "Epoch 83 completed - train_loss: 9355.813354 , test_loss: 10620.945312\n",
      "Epoch 83 training time: 5.711393\n",
      "Epoch 84 training started ...\n",
      "Epoch 84 completed - train_loss: 9354.737427 , test_loss: 10621.041016\n",
      "Epoch 84 training time: 5.743873\n",
      "Epoch 85 training started ...\n",
      "Epoch 85 completed - train_loss: 9354.196838 , test_loss: 10617.671875\n",
      "Epoch 85 training time: 5.701239\n",
      "Epoch 86 training started ...\n",
      "Epoch 86 completed - train_loss: 9353.277344 , test_loss: 10619.460938\n",
      "Epoch 86 training time: 5.695867\n",
      "Epoch 87 training started ...\n",
      "Epoch 87 completed - train_loss: 9352.679504 , test_loss: 10617.992188\n",
      "Epoch 87 training time: 5.701528\n",
      "Epoch 88 training started ...\n",
      "Epoch 88 completed - train_loss: 9352.164856 , test_loss: 10617.021484\n",
      "Epoch 88 training time: 5.702880\n",
      "Epoch 89 training started ...\n",
      "Epoch 89 completed - train_loss: 9351.673584 , test_loss: 10615.713867\n",
      "Epoch 89 training time: 5.719762\n",
      "Epoch 90 training started ...\n",
      "Epoch 90 completed - train_loss: 9351.134094 , test_loss: 10617.074219\n",
      "Epoch 90 training time: 5.723861\n",
      "Epoch 91 training started ...\n",
      "Epoch 91 completed - train_loss: 9351.050171 , test_loss: 10614.152344\n",
      "Epoch 91 training time: 5.693110\n",
      "Epoch 92 training started ...\n",
      "Epoch 92 completed - train_loss: 9350.600342 , test_loss: 10615.458984\n",
      "Epoch 92 training time: 5.686344\n",
      "Epoch 93 training started ...\n",
      "Epoch 93 completed - train_loss: 9350.399719 , test_loss: 10614.136719\n",
      "Epoch 93 training time: 5.698235\n",
      "Epoch 94 training started ...\n",
      "Epoch 94 completed - train_loss: 9350.190430 , test_loss: 10613.775391\n",
      "Epoch 94 training time: 5.697028\n",
      "Epoch 95 training started ...\n",
      "Epoch 95 completed - train_loss: 9349.817383 , test_loss: 10615.080078\n",
      "Epoch 95 training time: 5.693324\n",
      "Epoch 96 training started ...\n",
      "Epoch 96 completed - train_loss: 9349.776489 , test_loss: 10613.446289\n",
      "Epoch 96 training time: 5.703540\n",
      "Epoch 97 training started ...\n",
      "Epoch 97 completed - train_loss: 9349.611511 , test_loss: 10613.959961\n",
      "Epoch 97 training time: 5.659859\n",
      "Epoch 98 training started ...\n",
      "Epoch 98 completed - train_loss: 9349.447693 , test_loss: 10614.030273\n",
      "Epoch 98 training time: 5.634501\n",
      "Epoch 99 training started ...\n",
      "Epoch 99 completed - train_loss: 9349.288940 , test_loss: 10613.876953\n",
      "Epoch 99 training time: 5.644580\n",
      "Epoch 0 training started ...\n",
      "Epoch 0 completed - train_loss: 13680.330444 , test_loss: 18641.912109\n",
      "Epoch 0 training time: 5.239486\n",
      "Epoch 1 training started ...\n",
      "Epoch 1 completed - train_loss: 11176.632324 , test_loss: 18363.722656\n",
      "Epoch 1 training time: 5.290396\n",
      "Epoch 2 training started ...\n",
      "Epoch 2 completed - train_loss: 12560.559692 , test_loss: 15710.812500\n",
      "Epoch 2 training time: 5.253543\n",
      "Epoch 3 training started ...\n",
      "Epoch 3 completed - train_loss: 10581.338745 , test_loss: 14724.117188\n",
      "Epoch 3 training time: 5.261109\n",
      "Epoch 4 training started ...\n",
      "Epoch 4 completed - train_loss: 10159.194336 , test_loss: 15886.583984\n",
      "Epoch 4 training time: 5.275022\n",
      "Epoch 5 training started ...\n",
      "Epoch 5 completed - train_loss: 10803.945801 , test_loss: 17963.978516\n",
      "Epoch 5 training time: 5.270573\n",
      "Epoch 6 training started ...\n",
      "Epoch 6 completed - train_loss: 11255.224731 , test_loss: 20185.539062\n",
      "Epoch 6 training time: 5.341947\n",
      "Epoch 7 training started ...\n",
      "Epoch 7 completed - train_loss: 12757.221313 , test_loss: 18174.300781\n",
      "Epoch 7 training time: 5.347122\n",
      "Epoch 8 training started ...\n",
      "Epoch 8 completed - train_loss: 12917.414307 , test_loss: 15275.390625\n",
      "Epoch 8 training time: 5.338681\n",
      "Epoch 9 training started ...\n",
      "Epoch 9 completed - train_loss: 11040.836914 , test_loss: 18138.011719\n",
      "Epoch 9 training time: 5.337209\n",
      "Epoch 10 training started ...\n",
      "Epoch 10 completed - train_loss: 11361.345276 , test_loss: 17793.419922\n",
      "Epoch 10 training time: 5.354511\n",
      "Epoch 11 training started ...\n",
      "Epoch 11 completed - train_loss: 11112.916260 , test_loss: 13968.366211\n",
      "Epoch 11 training time: 5.404508\n",
      "Epoch 12 training started ...\n",
      "Epoch 12 completed - train_loss: 9973.886414 , test_loss: 15392.949219\n",
      "Epoch 12 training time: 5.406108\n",
      "Epoch 13 training started ...\n",
      "Epoch 13 completed - train_loss: 10861.450256 , test_loss: 13712.929688\n",
      "Epoch 13 training time: 5.341795\n",
      "Epoch 14 training started ...\n",
      "Epoch 14 completed - train_loss: 9839.505005 , test_loss: 16286.593750\n",
      "Epoch 14 training time: 5.323378\n",
      "Epoch 15 training started ...\n",
      "Epoch 15 completed - train_loss: 10543.829956 , test_loss: 15305.242188\n",
      "Epoch 15 training time: 5.339348\n",
      "Epoch 16 training started ...\n",
      "Epoch 16 completed - train_loss: 10748.113647 , test_loss: 17211.070312\n",
      "Epoch 16 training time: 5.332696\n",
      "Epoch 17 training started ...\n",
      "Epoch 17 completed - train_loss: 11316.970581 , test_loss: 16322.643555\n",
      "Epoch 17 training time: 5.384560\n",
      "Epoch 18 training started ...\n",
      "Epoch 18 completed - train_loss: 10209.613831 , test_loss: 16908.195312\n",
      "Epoch 18 training time: 5.410935\n",
      "Epoch 19 training started ...\n",
      "Epoch 19 completed - train_loss: 11284.934204 , test_loss: 19867.447266\n",
      "Epoch 19 training time: 5.362877\n",
      "Epoch 20 training started ...\n",
      "Epoch 20 completed - train_loss: 11812.909973 , test_loss: 20561.234375\n",
      "Epoch 20 training time: 5.365407\n",
      "Epoch 21 training started ...\n",
      "Epoch 21 completed - train_loss: 11850.168701 , test_loss: 16034.182617\n",
      "Epoch 21 training time: 5.364735\n",
      "Epoch 22 training started ...\n",
      "Epoch 22 completed - train_loss: 10584.118958 , test_loss: 13728.166016\n",
      "Epoch 22 training time: 5.358842\n",
      "Epoch 23 training started ...\n",
      "Epoch 23 completed - train_loss: 10992.524414 , test_loss: 15034.748047\n",
      "Epoch 23 training time: 5.355657\n",
      "Epoch 24 training started ...\n",
      "Epoch 24 completed - train_loss: 10214.270386 , test_loss: 13900.974609\n",
      "Epoch 24 training time: 5.398811\n",
      "Epoch 25 training started ...\n",
      "Epoch 25 completed - train_loss: 9535.638672 , test_loss: 13554.501953\n",
      "Epoch 25 training time: 5.328929\n",
      "Epoch 26 training started ...\n",
      "Epoch 26 completed - train_loss: 9870.552673 , test_loss: 13907.982422\n",
      "Epoch 26 training time: 5.331885\n",
      "Epoch 27 training started ...\n",
      "Epoch 27 completed - train_loss: 10250.230103 , test_loss: 15519.413086\n",
      "Epoch 27 training time: 5.316686\n",
      "Epoch 28 training started ...\n",
      "Epoch 28 completed - train_loss: 9962.420044 , test_loss: 13857.119141\n",
      "Epoch 28 training time: 5.299641\n",
      "Epoch 29 training started ...\n",
      "Epoch 29 completed - train_loss: 9778.770569 , test_loss: 13534.351562\n",
      "Epoch 29 training time: 5.255349\n",
      "Epoch 30 training started ...\n",
      "Epoch 30 completed - train_loss: 9466.047119 , test_loss: 14147.203125\n",
      "Epoch 30 training time: 5.270682\n",
      "Epoch 31 training started ...\n",
      "Epoch 31 completed - train_loss: 9693.406006 , test_loss: 13687.619141\n",
      "Epoch 31 training time: 5.254128\n",
      "Epoch 32 training started ...\n",
      "Epoch 32 completed - train_loss: 9552.129578 , test_loss: 15953.385742\n",
      "Epoch 32 training time: 5.244497\n",
      "Epoch 33 training started ...\n",
      "Epoch 33 completed - train_loss: 9940.506836 , test_loss: 13963.393555\n",
      "Epoch 33 training time: 5.259189\n",
      "Epoch 34 training started ...\n",
      "Epoch 34 completed - train_loss: 9673.077759 , test_loss: 13537.668945\n",
      "Epoch 34 training time: 5.264423\n",
      "Epoch 35 training started ...\n",
      "Epoch 35 completed - train_loss: 10052.471008 , test_loss: 15000.355469\n",
      "Epoch 35 training time: 5.391999\n",
      "Epoch 36 training started ...\n",
      "Epoch 36 completed - train_loss: 9761.166321 , test_loss: 14276.845703\n",
      "Epoch 36 training time: 5.288872\n",
      "Epoch 37 training started ...\n",
      "Epoch 37 completed - train_loss: 9532.210968 , test_loss: 14095.445312\n",
      "Epoch 37 training time: 5.286826\n",
      "Epoch 38 training started ...\n",
      "Epoch 38 completed - train_loss: 9618.948303 , test_loss: 14201.845703\n",
      "Epoch 38 training time: 5.287583\n",
      "Epoch 39 training started ...\n",
      "Epoch 39 completed - train_loss: 9440.784668 , test_loss: 14491.753906\n",
      "Epoch 39 training time: 5.270082\n",
      "Epoch 40 training started ...\n",
      "Epoch 40 completed - train_loss: 9610.552612 , test_loss: 14862.075195\n",
      "Epoch 40 training time: 5.266705\n",
      "Epoch 41 training started ...\n",
      "Epoch 41 completed - train_loss: 9991.062073 , test_loss: 13663.359375\n",
      "Epoch 41 training time: 5.236793\n",
      "Epoch 42 training started ...\n",
      "Epoch 42 completed - train_loss: 9471.461914 , test_loss: 14910.535156\n",
      "Epoch 42 training time: 5.263510\n",
      "Epoch 43 training started ...\n",
      "Epoch 43 completed - train_loss: 9825.587280 , test_loss: 14267.900391\n",
      "Epoch 43 training time: 5.267380\n",
      "Epoch 44 training started ...\n",
      "Epoch 44 completed - train_loss: 9949.665405 , test_loss: 15345.384766\n",
      "Epoch 44 training time: 5.263960\n",
      "Epoch 45 training started ...\n",
      "Epoch 45 completed - train_loss: 10224.217896 , test_loss: 14599.125000\n",
      "Epoch 45 training time: 5.280112\n",
      "Epoch 46 training started ...\n",
      "Epoch 46 completed - train_loss: 9673.327332 , test_loss: 14918.357422\n",
      "Epoch 46 training time: 5.278593\n",
      "Epoch 47 training started ...\n",
      "Epoch 47 completed - train_loss: 9624.947388 , test_loss: 13834.390625\n",
      "Epoch 47 training time: 5.268874\n",
      "Epoch 48 training started ...\n",
      "Epoch 48 completed - train_loss: 9487.828552 , test_loss: 13757.089844\n",
      "Epoch 48 training time: 5.249445\n",
      "Epoch 49 training started ...\n",
      "Epoch 49 completed - train_loss: 9644.032043 , test_loss: 14964.199219\n",
      "Epoch 49 training time: 5.273258\n",
      "Epoch 50 training started ...\n",
      "Epoch 50 completed - train_loss: 10081.788971 , test_loss: 15762.939453\n",
      "Epoch 50 training time: 5.253762\n",
      "Epoch 51 training started ...\n",
      "Epoch 51 completed - train_loss: 9886.824463 , test_loss: 13184.535156\n",
      "Epoch 51 training time: 5.253139\n",
      "Epoch 52 training started ...\n",
      "Epoch 52 completed - train_loss: 9296.282959 , test_loss: 14563.256836\n",
      "Epoch 52 training time: 5.287958\n",
      "Epoch 53 training started ...\n",
      "Epoch 53 completed - train_loss: 9547.772552 , test_loss: 14359.699219\n",
      "Epoch 53 training time: 5.253650\n",
      "Epoch 54 training started ...\n",
      "Epoch 54 completed - train_loss: 9764.915161 , test_loss: 14100.540039\n",
      "Epoch 54 training time: 5.271119\n",
      "Epoch 55 training started ...\n",
      "Epoch 55 completed - train_loss: 9317.980682 , test_loss: 13217.477539\n",
      "Epoch 55 training time: 5.269583\n",
      "Epoch 56 training started ...\n",
      "Epoch 56 completed - train_loss: 9354.007385 , test_loss: 13236.725586\n",
      "Epoch 56 training time: 5.263838\n",
      "Epoch 57 training started ...\n",
      "Epoch 57 completed - train_loss: 9282.943665 , test_loss: 14034.263672\n",
      "Epoch 57 training time: 5.258878\n",
      "Epoch 58 training started ...\n",
      "Epoch 58 completed - train_loss: 9616.026917 , test_loss: 13211.781250\n",
      "Epoch 58 training time: 5.259232\n",
      "Epoch 59 training started ...\n",
      "Epoch 59 completed - train_loss: 9770.382446 , test_loss: 14112.215820\n",
      "Epoch 59 training time: 5.274673\n",
      "Epoch 60 training started ...\n",
      "Epoch 60 completed - train_loss: 9779.229736 , test_loss: 15042.130859\n",
      "Epoch 60 training time: 5.265115\n",
      "Epoch 61 training started ...\n",
      "Epoch 61 completed - train_loss: 9801.761963 , test_loss: 14029.612305\n",
      "Epoch 61 training time: 5.346624\n",
      "Epoch 62 training started ...\n",
      "Epoch 62 completed - train_loss: 9607.008362 , test_loss: 13145.708008\n",
      "Epoch 62 training time: 5.327657\n",
      "Epoch 63 training started ...\n",
      "Epoch 63 completed - train_loss: 9836.158386 , test_loss: 13098.224609\n",
      "Epoch 63 training time: 5.326061\n",
      "Epoch 64 training started ...\n",
      "Epoch 64 completed - train_loss: 9145.454895 , test_loss: 13399.042969\n",
      "Epoch 64 training time: 5.340982\n",
      "Epoch 65 training started ...\n",
      "Epoch 65 completed - train_loss: 9272.868408 , test_loss: 13572.864258\n",
      "Epoch 65 training time: 5.341054\n",
      "Epoch 66 training started ...\n",
      "Epoch 66 completed - train_loss: 9221.353699 , test_loss: 13424.926758\n",
      "Epoch 66 training time: 5.342663\n",
      "Epoch 67 training started ...\n",
      "Epoch 67 completed - train_loss: 9285.101929 , test_loss: 13850.257812\n",
      "Epoch 67 training time: 5.344098\n",
      "Epoch 68 training started ...\n",
      "Epoch 68 completed - train_loss: 9417.205750 , test_loss: 13103.527344\n",
      "Epoch 68 training time: 5.338320\n",
      "Epoch 69 training started ...\n",
      "Epoch 69 completed - train_loss: 9115.365112 , test_loss: 13376.039062\n",
      "Epoch 69 training time: 5.418154\n",
      "Epoch 70 training started ...\n",
      "Epoch 70 completed - train_loss: 9223.418549 , test_loss: 13479.546875\n",
      "Epoch 70 training time: 5.364685\n",
      "Epoch 71 training started ...\n",
      "Epoch 71 completed - train_loss: 9181.399261 , test_loss: 13307.823242\n",
      "Epoch 71 training time: 5.374578\n",
      "Epoch 72 training started ...\n",
      "Epoch 72 completed - train_loss: 9246.988403 , test_loss: 13609.796875\n",
      "Epoch 72 training time: 5.389835\n",
      "Epoch 73 training started ...\n",
      "Epoch 73 completed - train_loss: 9329.236023 , test_loss: 13137.681641\n",
      "Epoch 73 training time: 5.392590\n",
      "Epoch 74 training started ...\n",
      "Epoch 74 completed - train_loss: 9287.221008 , test_loss: 13639.003906\n",
      "Epoch 74 training time: 5.303663\n",
      "Epoch 75 training started ...\n",
      "Epoch 75 completed - train_loss: 9232.518860 , test_loss: 13467.778320\n",
      "Epoch 75 training time: 5.376539\n",
      "Epoch 76 training started ...\n",
      "Epoch 76 completed - train_loss: 9168.722961 , test_loss: 13373.530273\n",
      "Epoch 76 training time: 5.322858\n",
      "Epoch 77 training started ...\n",
      "Epoch 77 completed - train_loss: 9145.270874 , test_loss: 13170.501953\n",
      "Epoch 77 training time: 5.350710\n",
      "Epoch 78 training started ...\n",
      "Epoch 78 completed - train_loss: 9131.353973 , test_loss: 13339.235352\n",
      "Epoch 78 training time: 5.283439\n",
      "Epoch 79 training started ...\n",
      "Epoch 79 completed - train_loss: 9223.605164 , test_loss: 13276.158203\n",
      "Epoch 79 training time: 5.277445\n",
      "Epoch 80 training started ...\n",
      "Epoch 80 completed - train_loss: 9218.092560 , test_loss: 13377.693359\n",
      "Epoch 80 training time: 5.288191\n",
      "Epoch 81 training started ...\n",
      "Epoch 81 completed - train_loss: 9158.645996 , test_loss: 13704.906250\n",
      "Epoch 81 training time: 5.289876\n",
      "Epoch 82 training started ...\n",
      "Epoch 82 completed - train_loss: 9334.471161 , test_loss: 14181.692383\n",
      "Epoch 82 training time: 5.342807\n",
      "Epoch 83 training started ...\n",
      "Epoch 83 completed - train_loss: 9435.026123 , test_loss: 13569.990234\n",
      "Epoch 83 training time: 5.350350\n",
      "Epoch 84 training started ...\n",
      "Epoch 84 completed - train_loss: 9215.022858 , test_loss: 13043.601562\n",
      "Epoch 84 training time: 5.325424\n",
      "Epoch 85 training started ...\n",
      "Epoch 85 completed - train_loss: 9215.799377 , test_loss: 13491.740234\n",
      "Epoch 85 training time: 5.356007\n",
      "Epoch 86 training started ...\n",
      "Epoch 86 completed - train_loss: 9318.455627 , test_loss: 13318.149414\n",
      "Epoch 86 training time: 5.292910\n",
      "Epoch 87 training started ...\n",
      "Epoch 87 completed - train_loss: 9100.729736 , test_loss: 13161.905273\n",
      "Epoch 87 training time: 5.311627\n",
      "Epoch 88 training started ...\n",
      "Epoch 88 completed - train_loss: 9068.170837 , test_loss: 13129.638672\n",
      "Epoch 88 training time: 5.376950\n",
      "Epoch 89 training started ...\n",
      "Epoch 89 completed - train_loss: 9067.753265 , test_loss: 13212.341797\n",
      "Epoch 89 training time: 5.341213\n",
      "Epoch 90 training started ...\n",
      "Epoch 90 completed - train_loss: 9108.433167 , test_loss: 13180.464844\n",
      "Epoch 90 training time: 5.271256\n",
      "Epoch 91 training started ...\n",
      "Epoch 91 completed - train_loss: 9113.643555 , test_loss: 13128.714844\n",
      "Epoch 91 training time: 5.276302\n",
      "Epoch 92 training started ...\n",
      "Epoch 92 completed - train_loss: 9085.155243 , test_loss: 13295.628906\n",
      "Epoch 92 training time: 5.261786\n",
      "Epoch 93 training started ...\n",
      "Epoch 93 completed - train_loss: 9079.610138 , test_loss: 13167.374023\n",
      "Epoch 93 training time: 5.230370\n",
      "Epoch 94 training started ...\n",
      "Epoch 94 completed - train_loss: 9053.611084 , test_loss: 13097.581055\n",
      "Epoch 94 training time: 5.258936\n",
      "Epoch 95 training started ...\n",
      "Epoch 95 completed - train_loss: 9037.763855 , test_loss: 13059.714844\n",
      "Epoch 95 training time: 5.302590\n",
      "Epoch 96 training started ...\n",
      "Epoch 96 completed - train_loss: 9033.842957 , test_loss: 13124.556641\n",
      "Epoch 96 training time: 5.253987\n",
      "Epoch 97 training started ...\n",
      "Epoch 97 completed - train_loss: 9053.797211 , test_loss: 13126.191406\n",
      "Epoch 97 training time: 5.238344\n",
      "Epoch 98 training started ...\n",
      "Epoch 98 completed - train_loss: 9063.789886 , test_loss: 13022.185547\n",
      "Epoch 98 training time: 5.266665\n",
      "Epoch 99 training started ...\n",
      "Epoch 99 completed - train_loss: 9049.854309 , test_loss: 13109.263672\n",
      "Epoch 99 training time: 5.305621\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    # Training:\n",
    "    train_losses, test_losses = training(model, optimizer, train_loader[i], val_loader[i], epochs)\n",
    "\n",
    "    # Saving trained models\n",
    "    torch.save(model, f'./model/sensor_model_{i}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate result on public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "# load val data\n",
    "df_sensorA_public = pd.read_csv('data/sensor_A_public.csv')\n",
    "df_sensorB_public = pd.read_csv('data/sensor_B_public.csv')\n",
    "df_sensorC_public = pd.read_csv('data/sensor_C_public.csv')\n",
    "df_sensorD_public = pd.read_csv('data/sensor_D_public.csv')\n",
    "df_sensorE_public = pd.read_csv('data/sensor_E_public.csv')\n",
    "print(len(df_sensorA_public))\n",
    "df_test = [df_sensorA_public, df_sensorB_public, df_sensorC_public, df_sensorD_public, df_sensorE_public]\n",
    "target = []\n",
    "for df in df_test:\n",
    "    target.append(df.iloc[:, -1].values)\n",
    "    df.drop(df.index[-1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = []\n",
    "for df in df_test:\n",
    "    data = np.array(df.iloc[:, 0].values).astype(float).reshape(-1, 1)\n",
    "    val_dataset.append(SensorDataset(data, seq_len=data_seq_len, transform = data_transform))\n",
    "val_loader = []\n",
    "for dataset in val_dataset:\n",
    "    val_loader.append(DataLoader(dataset, batch_size=batch_size, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_133422/3831346761.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./model/sensor_model_{i}.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mreconstructed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstructed_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0morigin_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_133422/855929745.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, dataset_iterator)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# sum of all seq_len losses into one loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# reshape to (batch, seq_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    model = torch.load(f'./model/sensor_model_{i}.pth')\n",
    "    reconstructed_val, losses_val = predict(model, val_loader[i])\n",
    "    print(reconstructed_val.shape)\n",
    "    origin_data = val_dataset[i].dataset\n",
    "    print(origin_data)\n",
    "    reconstructed_error = np.abs((reconstructed_val - origin_data))\n",
    "    print(\"reconstructed_error:\", reconstructed_error.shape)\n",
    "    print(\"AUC score:\", roc_auc_score(target[i], reconstructed_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate private result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
